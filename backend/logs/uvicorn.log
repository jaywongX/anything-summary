INFO:     Will watch for changes in these directories: ['/mnt/d/git/anything-summary/backend']
INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)
INFO:     Started reloader process [13261] using StatReload
[2025-01-31 11:49:30,601: INFO/SpawnProcess-1] Tesseract is available
[2025-01-31 11:49:30,602: WARNING/SpawnProcess-1] Chinese language pack not found
[2025-01-31 11:49:30,603: INFO/SpawnProcess-1] pdf2image (poppler) is available
[2025-01-31 11:49:30,604: INFO/SpawnProcess-1] PyCryptodome is available
Redis version: 7.0.15
Connected clients: 1
Used memory: 1.47M
INFO:     Started server process [13264]
INFO:     Waiting for application startup.
[2025-01-31 11:49:32,389: INFO/SpawnProcess-1] Starting up application...
[2025-01-31 11:49:32,465: INFO/SpawnProcess-1] Registered tasks: dict_keys(['celery.starmap', 'celery.accumulate', 'celery.chord', 'celery.chunks', 'celery.chord_unlock', 'celery.group', 'celery.map', 'celery.backend_cleanup', 'app.core.tasks.process_and_summarize', 'celery.chain'])
INFO:     Application startup complete.
[2025-01-31 11:49:37,838: DEBUG/SpawnProcess-1] Task 5597b756-2752-4755-8051-9ad8e59f73fb state: PENDING
[2025-01-31 11:49:37,839: DEBUG/SpawnProcess-1] Redis result for task 5597b756-2752-4755-8051-9ad8e59f73fb: {'status': 'PENDING', 'result': None}
INFO:     127.0.0.1:43020 - "GET /api/summary/5597b756-2752-4755-8051-9ad8e59f73fb HTTP/1.1" 200 OK
[2025-01-31 11:49:38,852: DEBUG/SpawnProcess-1] Task 5597b756-2752-4755-8051-9ad8e59f73fb state: PENDING
[2025-01-31 11:49:38,853: DEBUG/SpawnProcess-1] Redis result for task 5597b756-2752-4755-8051-9ad8e59f73fb: {'status': 'PENDING', 'result': None}
INFO:     127.0.0.1:43020 - "GET /api/summary/5597b756-2752-4755-8051-9ad8e59f73fb HTTP/1.1" 200 OK
[2025-01-31 11:49:39,867: DEBUG/SpawnProcess-1] Task 5597b756-2752-4755-8051-9ad8e59f73fb state: PENDING
[2025-01-31 11:49:39,868: DEBUG/SpawnProcess-1] Redis result for task 5597b756-2752-4755-8051-9ad8e59f73fb: {'status': 'PENDING', 'result': None}
INFO:     127.0.0.1:43020 - "GET /api/summary/5597b756-2752-4755-8051-9ad8e59f73fb HTTP/1.1" 200 OK
[2025-01-31 11:49:40,882: DEBUG/SpawnProcess-1] Task 5597b756-2752-4755-8051-9ad8e59f73fb state: PENDING
[2025-01-31 11:49:40,884: DEBUG/SpawnProcess-1] Redis result for task 5597b756-2752-4755-8051-9ad8e59f73fb: {'status': 'PENDING', 'result': None}
INFO:     127.0.0.1:43020 - "GET /api/summary/5597b756-2752-4755-8051-9ad8e59f73fb HTTP/1.1" 200 OK
[2025-01-31 11:49:41,899: DEBUG/SpawnProcess-1] Task 5597b756-2752-4755-8051-9ad8e59f73fb state: PENDING
[2025-01-31 11:49:41,901: DEBUG/SpawnProcess-1] Redis result for task 5597b756-2752-4755-8051-9ad8e59f73fb: {'status': 'PENDING', 'result': None}
INFO:     127.0.0.1:43020 - "GET /api/summary/5597b756-2752-4755-8051-9ad8e59f73fb HTTP/1.1" 200 OK
[2025-01-31 11:49:47,258: DEBUG/SpawnProcess-1] Calling on_part_begin with no data
[2025-01-31 11:49:47,259: DEBUG/SpawnProcess-1] Calling on_header_field with data[42:61]
[2025-01-31 11:49:47,260: DEBUG/SpawnProcess-1] Calling on_header_value with data[63:85]
[2025-01-31 11:49:47,260: DEBUG/SpawnProcess-1] Calling on_header_end with no data
[2025-01-31 11:49:47,261: DEBUG/SpawnProcess-1] Calling on_headers_finished with no data
[2025-01-31 11:49:47,262: DEBUG/SpawnProcess-1] Calling on_part_data with data[89:90]
[2025-01-31 11:49:47,263: DEBUG/SpawnProcess-1] Calling on_part_end with no data
[2025-01-31 11:49:47,263: DEBUG/SpawnProcess-1] Calling on_end with no data
[2025-01-31 11:49:47,264: INFO/SpawnProcess-1] Received request - files: False, text: True, url: False
[2025-01-31 11:49:47,265: INFO/SpawnProcess-1] Creating new task with ID: 5b1eef05-d94f-4f23-a5f4-950eeade43ac
[2025-01-31 11:49:47,424: INFO/SpawnProcess-1] Created celery task with ID: 5b1eef05-d94f-4f23-a5f4-950eeade43ac
INFO:     127.0.0.1:43034 - "POST /api/summary HTTP/1.1" 200 OK
[2025-01-31 11:49:47,437: DEBUG/SpawnProcess-1] Task 5b1eef05-d94f-4f23-a5f4-950eeade43ac state: PENDING
[2025-01-31 11:49:47,438: DEBUG/SpawnProcess-1] Redis result for task 5b1eef05-d94f-4f23-a5f4-950eeade43ac: {'status': 'PENDING', 'result': None}
INFO:     127.0.0.1:43034 - "GET /api/summary/5b1eef05-d94f-4f23-a5f4-950eeade43ac HTTP/1.1" 200 OK
[2025-01-31 11:49:50,459: DEBUG/SpawnProcess-1] Calling on_part_begin with no data
[2025-01-31 11:49:50,460: DEBUG/SpawnProcess-1] Calling on_header_field with data[42:61]
[2025-01-31 11:49:50,461: DEBUG/SpawnProcess-1] Calling on_header_value with data[63:85]
[2025-01-31 11:49:50,462: DEBUG/SpawnProcess-1] Calling on_header_end with no data
[2025-01-31 11:49:50,463: DEBUG/SpawnProcess-1] Calling on_headers_finished with no data
[2025-01-31 11:49:50,464: DEBUG/SpawnProcess-1] Calling on_part_data with data[89:90]
[2025-01-31 11:49:50,464: DEBUG/SpawnProcess-1] Calling on_part_end with no data
[2025-01-31 11:49:50,465: DEBUG/SpawnProcess-1] Calling on_end with no data
[2025-01-31 11:49:50,465: INFO/SpawnProcess-1] Received request - files: False, text: True, url: False
[2025-01-31 11:49:50,466: INFO/SpawnProcess-1] Creating new task with ID: e88e2cc4-7c57-442d-9b09-ef27db07c0d0
[2025-01-31 11:49:50,475: INFO/SpawnProcess-1] Created celery task with ID: e88e2cc4-7c57-442d-9b09-ef27db07c0d0
INFO:     127.0.0.1:43034 - "POST /api/summary HTTP/1.1" 200 OK
[2025-01-31 11:49:50,502: DEBUG/SpawnProcess-1] Task e88e2cc4-7c57-442d-9b09-ef27db07c0d0 state: SUCCESS
[2025-01-31 11:49:50,503: DEBUG/SpawnProcess-1] Redis result for task e88e2cc4-7c57-442d-9b09-ef27db07c0d0: {'status': 'SUCCESS', 'result': {'status': 'success', 'summary': '文本内容:\n2'}, 'traceback': None, 'children': [], 'date_done': '2025-01-31T03:49:50.485111', 'task_id': 'e88e2cc4-7c57-442d-9b09-ef27db07c0d0'}
INFO:     127.0.0.1:43034 - "GET /api/summary/e88e2cc4-7c57-442d-9b09-ef27db07c0d0 HTTP/1.1" 200 OK
[2025-01-31 11:49:52,631: DEBUG/SpawnProcess-1] Calling on_part_begin with no data
[2025-01-31 11:49:52,631: DEBUG/SpawnProcess-1] Calling on_header_field with data[42:61]
[2025-01-31 11:49:52,632: DEBUG/SpawnProcess-1] Calling on_header_value with data[63:85]
[2025-01-31 11:49:52,632: DEBUG/SpawnProcess-1] Calling on_header_end with no data
[2025-01-31 11:49:52,633: DEBUG/SpawnProcess-1] Calling on_headers_finished with no data
[2025-01-31 11:49:52,634: DEBUG/SpawnProcess-1] Calling on_part_data with data[89:90]
[2025-01-31 11:49:52,634: DEBUG/SpawnProcess-1] Calling on_part_end with no data
[2025-01-31 11:49:52,635: DEBUG/SpawnProcess-1] Calling on_end with no data
[2025-01-31 11:49:52,635: INFO/SpawnProcess-1] Received request - files: False, text: True, url: False
[2025-01-31 11:49:52,636: INFO/SpawnProcess-1] Creating new task with ID: 9c3012bd-dcc8-4e56-a6e6-ca918feafb91
[2025-01-31 11:49:52,642: INFO/SpawnProcess-1] Created celery task with ID: 9c3012bd-dcc8-4e56-a6e6-ca918feafb91
INFO:     127.0.0.1:43034 - "POST /api/summary HTTP/1.1" 200 OK
[2025-01-31 11:49:52,652: DEBUG/SpawnProcess-1] Task 9c3012bd-dcc8-4e56-a6e6-ca918feafb91 state: PENDING
[2025-01-31 11:49:52,654: DEBUG/SpawnProcess-1] Redis result for task 9c3012bd-dcc8-4e56-a6e6-ca918feafb91: {'status': 'PENDING', 'result': None}
INFO:     127.0.0.1:43034 - "GET /api/summary/9c3012bd-dcc8-4e56-a6e6-ca918feafb91 HTTP/1.1" 200 OK
[2025-01-31 11:49:53,716: DEBUG/SpawnProcess-1] Task 9c3012bd-dcc8-4e56-a6e6-ca918feafb91 state: SUCCESS
[2025-01-31 11:49:53,717: DEBUG/SpawnProcess-1] Redis result for task 9c3012bd-dcc8-4e56-a6e6-ca918feafb91: {'status': 'SUCCESS', 'result': {'status': 'success', 'summary': '文本内容:\n3'}, 'traceback': None, 'children': [], 'date_done': '2025-01-31T03:49:52.653933', 'task_id': '9c3012bd-dcc8-4e56-a6e6-ca918feafb91'}
INFO:     127.0.0.1:43034 - "GET /api/summary/9c3012bd-dcc8-4e56-a6e6-ca918feafb91 HTTP/1.1" 200 OK
[2025-01-31 11:49:59,848: DEBUG/SpawnProcess-1] Calling on_part_begin with no data
[2025-01-31 11:49:59,848: DEBUG/SpawnProcess-1] Calling on_header_field with data[42:61]
[2025-01-31 11:49:59,849: DEBUG/SpawnProcess-1] Calling on_header_value with data[63:85]
[2025-01-31 11:49:59,850: DEBUG/SpawnProcess-1] Calling on_header_end with no data
[2025-01-31 11:49:59,850: DEBUG/SpawnProcess-1] Calling on_headers_finished with no data
[2025-01-31 11:49:59,851: DEBUG/SpawnProcess-1] Calling on_part_data with data[89:90]
[2025-01-31 11:49:59,852: DEBUG/SpawnProcess-1] Calling on_part_end with no data
[2025-01-31 11:49:59,852: DEBUG/SpawnProcess-1] Calling on_end with no data
[2025-01-31 11:49:59,853: INFO/SpawnProcess-1] Received request - files: False, text: True, url: False
[2025-01-31 11:49:59,853: INFO/SpawnProcess-1] Creating new task with ID: 20742c75-5801-47a8-81ae-ea77de82b5db
[2025-01-31 11:49:59,861: INFO/SpawnProcess-1] Created celery task with ID: 20742c75-5801-47a8-81ae-ea77de82b5db
INFO:     127.0.0.1:40852 - "POST /api/summary HTTP/1.1" 200 OK
[2025-01-31 11:49:59,868: DEBUG/SpawnProcess-1] Task 20742c75-5801-47a8-81ae-ea77de82b5db state: PENDING
[2025-01-31 11:49:59,869: DEBUG/SpawnProcess-1] Redis result for task 20742c75-5801-47a8-81ae-ea77de82b5db: {'status': 'SUCCESS', 'result': {'status': 'success', 'summary': '文本内容:\n4'}, 'traceback': None, 'children': [], 'date_done': '2025-01-31T03:49:59.868128', 'task_id': '20742c75-5801-47a8-81ae-ea77de82b5db'}
INFO:     127.0.0.1:40852 - "GET /api/summary/20742c75-5801-47a8-81ae-ea77de82b5db HTTP/1.1" 200 OK
[2025-01-31 11:50:23,759: DEBUG/SpawnProcess-1] Calling on_part_begin with no data
[2025-01-31 11:50:23,760: DEBUG/SpawnProcess-1] Calling on_header_field with data[42:61]
[2025-01-31 11:50:23,760: DEBUG/SpawnProcess-1] Calling on_header_value with data[63:114]
[2025-01-31 11:50:23,761: DEBUG/SpawnProcess-1] Calling on_header_end with no data
[2025-01-31 11:50:23,762: DEBUG/SpawnProcess-1] Calling on_header_field with data[116:128]
[2025-01-31 11:50:23,762: DEBUG/SpawnProcess-1] Calling on_header_value with data[130:140]
[2025-01-31 11:50:23,763: DEBUG/SpawnProcess-1] Calling on_header_end with no data
[2025-01-31 11:50:23,763: DEBUG/SpawnProcess-1] Calling on_headers_finished with no data
[2025-01-31 11:50:23,765: DEBUG/SpawnProcess-1] Calling on_part_data with data[144:16762]
[2025-01-31 11:50:23,765: DEBUG/SpawnProcess-1] Calling on_part_end with no data
[2025-01-31 11:50:23,766: DEBUG/SpawnProcess-1] Calling on_end with no data
[2025-01-31 11:50:23,767: INFO/SpawnProcess-1] Received request - files: True, text: False, url: False
[2025-01-31 11:50:23,768: INFO/SpawnProcess-1] Creating new task with ID: d841b3b0-9355-48da-814a-5999640a9df6
[2025-01-31 11:50:23,776: INFO/SpawnProcess-1] Saved file: uploads/d841b3b0-9355-48da-814a-5999640a9df6_summary (1).txt
[2025-01-31 11:50:23,811: INFO/SpawnProcess-1] Created celery task with ID: d841b3b0-9355-48da-814a-5999640a9df6
INFO:     127.0.0.1:40864 - "POST /api/summary HTTP/1.1" 200 OK
[2025-01-31 11:50:23,820: DEBUG/SpawnProcess-1] Task d841b3b0-9355-48da-814a-5999640a9df6 state: PENDING
[2025-01-31 11:50:23,821: DEBUG/SpawnProcess-1] Redis result for task d841b3b0-9355-48da-814a-5999640a9df6: {'status': 'PENDING', 'result': None}
INFO:     127.0.0.1:40864 - "GET /api/summary/d841b3b0-9355-48da-814a-5999640a9df6 HTTP/1.1" 200 OK
[2025-01-31 11:50:25,206: DEBUG/SpawnProcess-1] Task d841b3b0-9355-48da-814a-5999640a9df6 state: SUCCESS
[2025-01-31 11:50:25,208: DEBUG/SpawnProcess-1] Redis result for task d841b3b0-9355-48da-814a-5999640a9df6: {'status': 'SUCCESS', 'result': {'status': 'success', 'summary': '文件 d841b3b0-9355-48da-814a-5999640a9df6_summary (1).txt 内容:\n文件 5b26444d-955b-4951-a2cf-fb65c027796a_CMakeLists.txt 内容:\ncmake_minimum_required(VERSION 3.15)\nproject(cpr VERSION 1.8.1 LANGUAGES CXX)\n\nmath(EXPR cpr_VERSION_NUM "${cpr_VERSION_MAJOR} * 0x10000 + ${cpr_VERSION_MINOR} * 0x100 + ${cpr_VERSION_PATCH}" OUTPUT_FORMAT HEXADECIMAL)\nconfigure_file("${cpr_SOURCE_DIR}/cmake/cprver.h.in" "${cpr_BINARY_DIR}/cpr_generated_includes/cpr/cprver.h")\n\n# Only change the folder behaviour if cpr is not a subproject\nif(${CMAKE_PROJECT_NAME} STREQUAL ${PROJECT_NAME})\n    set_property(GLOBAL PROPERTY USE_FOLDERS ON)\n    set_property(GLOBAL PROPERTY PREDEFINED_TARGETS_FOLDER "CMake")\n    set(EXECUTABLE_OUTPUT_PATH ${CMAKE_BINARY_DIR}/bin)\n    set(LIBRARY_OUTPUT_PATH ${CMAKE_BINARY_DIR}/lib)\nendif()\n\n# Avoid the dll boilerplate code for windows\nset(CMAKE_WINDOWS_EXPORT_ALL_SYMBOLS ON)\nset(CMAKE_CXX_STANDARD 11)\nset(CMAKE_CXX_STANDARD_REQUIRED ON)\n\nset(CPR_LIBRARIES cpr CACHE INTERNAL "")\n\nmacro(cpr_option OPTION_NAME OPTION_TEXT OPTION_DEFAULT)\n    option(${OPTION_NAME} ${OPTION_TEXT} ${OPTION_DEFAULT})\n    if(DEFINED ENV{${OPTION_NAME}})\n        # Allow overriding the option through an environment variable\n        set(${OPTION_NAME} $ENV{${OPTION_NAME}})\n    endif()\n    if(${OPTION_NAME})\n        add_definitions(-D${OPTION_NAME})\n    endif()\n    message(STATUS "  ${OPTION_NAME}: ${${OPTION_NAME}}")\nendmacro()\n\noption(BUILD_SHARED_LIBS "Build libraries as shared libraries" ON)\nmessage(STATUS "C++ Requests CMake Options")\nmessage(STATUS "=======================================================")\ncpr_option(CPR_GENERATE_COVERAGE "Set to ON to generate coverage reports." OFF)\ncpr_option(CPR_CURL_NOSIGNAL "Set to ON to disable use of signals in libcurl." OFF)\ncpr_option(CPR_USE_SYSTEM_GTEST "If ON, this project will look in the system paths for an installed gtest library. If none is found it will use the build in one." OFF)\ncpr_option(CPR_FORCE_USE_SYSTEM_CURL "If enabled we will use the curl lib already installed on this system." OFF)\ncpr_option(CPR_ENABLE_SSL "Enables or disables the SSL backend. Required to perform HTTPS requests." ON)\ncpr_option(CPR_FORCE_OPENSSL_BACKEND "Force to use the OpenSSL backend. If CPR_FORCE_OPENSSL_BACKEND, CPR_FORCE_DARWINSSL_BACKEND, CPR_FORCE_MBEDTLS_BACKEND, and CPR_FORCE_WINSSL_BACKEND are set to to OFF, cpr will try to automatically detect the best available SSL backend (WinSSL - Windows, OpenSSL - Linux, DarwinSSL - Mac ...)." OFF)\ncpr_option(CPR_FORCE_WINSSL_BACKEND "Force to use the WinSSL backend. If CPR_FORCE_OPENSSL_BACKEND, CPR_FORCE_DARWINSSL_BACKEND, CPR_FORCE_MBEDTLS_BACKEND, and CPR_FORCE_WINSSL_BACKEND are set to to OFF, cpr will try to automatically detect the best available SSL backend (WinSSL - Windows, OpenSSL - Linux, DarwinSSL - Mac ...)." OFF)\ncpr_option(CPR_FORCE_DARWINSSL_BACKEND "Force to use the DarwinSSL backend. If CPR_FORCE_OPENSSL_BACKEND, CPR_FORCE_DARWINSSL_BACKEND, CPR_FORCE_MBEDTLS_BACKEND, and CPR_FORCE_WINSSL_BACKEND are set to to OFF, cpr will try to automatically detect the best available SSL backend (WinSSL - Windows, OpenSSL - Linux, DarwinSSL - Mac ...)." OFF)\ncpr_option(CPR_FORCE_MBEDTLS_BACKEND "Force to use the Mbed TLS backend. If CPR_FORCE_OPENSSL_BACKEND, CPR_FORCE_DARWINSSL_BACKEND, CPR_FORCE_MBEDTLS_BACKEND, and CPR_FORCE_WINSSL_BACKEND are set to to OFF, cpr will try to automatically detect the best available SSL backend (WinSSL - Windows, OpenSSL - Linux, DarwinSSL - Mac ...)." OFF)\ncpr_option(CPR_ENABLE_LINTING "Set to ON to enable clang linting." OFF)\ncpr_option(CPR_ENABLE_CPPCHECK "Set to ON to enable Cppcheck static analysis. Requires CPR_BUILD_TESTS and CPR_BUILD_TESTS_SSL to be OFF to prevent checking google tests source code." OFF)\ncpr_option(CPR_BUILD_TESTS "Set to ON to build cpr tests." OFF)\ncpr_option(CPR_BUILD_TESTS_SSL "Set to ON to build cpr ssl tests" ${CPR_BUILD_TESTS})\nmessage(STATUS "=======================================================")\n\ninclude(GNUInstallDirs)\ninclude(FetchContent)\ninclude(cmake/code_coverage.cmake)\ninclude(cmake/sanitizer.cmake)\ninclude(cmake/clear_variable.cmake)\n\n# So CMake can find FindMbedTLS.cmake\nset(CMAKE_MODULE_PATH "${CMAKE_CURRENT_SOURCE_DIR}/cmake;${CMAKE_MODULE_PATH}")\n\n# Linting\nif(CPR_ENABLE_LINTING)\n    include(cmake/clang-tidy.cmake)\nendif()\n\n# Cppcheck\nif(CPR_ENABLE_CPPCHECK)\n    if(CPR_BUILD_TESTS OR CPR_BUILD_TESTS_SSL)\n        message(FATAL_ERROR "Cppcheck is incompatible with building tests. Make sure to disable CPR_ENABLE_CPPCHECK or disable tests by setting CPR_BUILD_TESTS and CPR_BUILD_TESTS_SSL to OFF. This is because Cppcheck would try to check the google tests source code and then fail. ")\n    endif()\n    include(cmake/cppcheck.cmake)\nendif()\n\nif ("${CMAKE_CXX_COMPILER_ID}" STREQUAL "MSVC")\nelse()\n    set(CMAKE_CXX_FLAGS "${CMAKE_CXX_FLAGS} -Wall -Wextra -Wpedantic -Werror")\nendif()\n\n# SSL\nif(CPR_ENABLE_SSL)\n    if(CPR_FORCE_OPENSSL_BACKEND OR CPR_FORCE_WINSSL_BACKEND OR CPR_FORCE_DARWINSSL_BACKEND OR CPR_FORCE_MBEDTLS_BACKEND)\n        message(STATUS "Disabled SSL backend auto detect since either CPR_FORCE_OPENSSL_BACKEND, CPR_FORCE_DARWINSSL_BACKEND, CPR_FORCE_MBEDTLS_BACKEND, or CPR_FORCE_WINSSL_BACKEND is enabled.")\n        set(DETECT_SSL_BACKEND OFF CACHE INTERNAL "" FORCE)\n    else()\n        message(STATUS "Automatically detecting SSL backend.")\n        set(DETECT_SSL_BACKEND ON CACHE INTERNAL "" FORCE)\n    endif()\n\n    if(CPR_FORCE_WINSSL_BACKEND AND (NOT WIN32))\n        message(FATAL_ERROR "WinSSL is only available on Windows! Use either OpenSSL (CPR_FORCE_OPENSSL_BACKEND) or DarwinSSL (CPR_FORCE_DARWINSSL_BACKEND) instead.")\n    endif()\n\n    if(DETECT_SSL_BACKEND)\n        message(STATUS "Detecting SSL backend...")\n        if(WIN32)\n            message(STATUS "SSL auto detect: Using WinSSL.")\n            set(SSL_BACKEND_USED "WinSSL")\n        elseif(APPLE)\n            message(STATUS "SSL auto detect: Using DarwinSSL.")\n            set(CPR_BUILD_TESTS_SSL OFF)\n            set(SSL_BACKEND_USED "DarwinSSL")\n        else()\n            find_package(OpenSSL)\n            if(OPENSSL_FOUND)\n                message(STATUS "SSL auto detect: Using OpenSSL.")\n                set(SSL_BACKEND_USED "OpenSSL")\n            else()\n                find_package(MbedTLS)\n                if(MBEDTLS_FOUND)\n                    set(SSL_BACKEND_USED "MbedTLS")\n                else()\n                    message(FATAL_ERROR "No valid SSL backend found! Please install OpenSSL, Mbed TLS or disable SSL by setting CPR_ENABLE_SSL to OFF.")\n                endif()\n            endif()\n        endif()\n    else()\n        if(CPR_FORCE_OPENSSL_BACKEND)\n            find_package(OpenSSL)\n            if(OPENSSL_FOUND)\n                message(STATUS "Using OpenSSL.")\n                set(SSL_BACKEND_USED "OpenSSL")\n            else()\n                message(FATAL_ERROR "CPR_FORCE_OPENSSL_BACKEND enabled but we were not able to find OpenSSL!")\n            endif()\n        elseif(CPR_FORCE_WINSSL_BACKEND)\n            message(STATUS "Using WinSSL.")\n            set(SSL_BACKEND_USED "WinSSL")\n        elseif(CPR_FORCE_DARWINSSL_BACKEND)\n            message(STATUS "Using DarwinSSL.")\n            set(CPR_BUILD_TESTS_SSL OFF)\n            set(SSL_BACKEND_USED "DarwinSSL")\n        elseif(CPR_FORCE_MBEDTLS_BACKEND)\n            message(STATUS "Using Mbed TLS.")\n            set(CPR_BUILD_TESTS_SSL OFF)\n            set(SSL_BACKEND_USED "MbedTLS")\n        endif()\n    endif()\nendif()\n\nget_property(isMultiConfig GLOBAL PROPERTY GENERATOR_IS_MULTI_CONFIG)\nif (NOT isMultiConfig)\n    set_property(CACHE CMAKE_BUILD_TYPE PROPERTY STRINGS "${ALLOWED_BUILD_TYPES}")\n    if (NOT CMAKE_BUILD_TYPE)\n        set(CMAKE_BUILD_TYPE Debug CACHE STRING "" FORCE)\n    elseif(NOT CMAKE_BUILD_TYPE IN_LIST ALLOWED_BUILD_TYPES)\n        message(FATAL_ERROR "Invalid build type: ${CMAKE_BUILD_TYPE}")\n    endif()\nelse ()\n    unset(CMAKE_BUILD_TYPE)\n    foreach(TYPE ${ALLOWED_BUILD_TYPES})\n        if (NOT ${TYPE} IN_LIST CMAKE_CONFIGURATION_TYPES)\n            list(APPEND CMAKE_CONFIGURATION_TYPES ${TYPE})\n        endif()\n    endforeach()\nendif()\n\n# Curl configuration\nif(CPR_FORCE_USE_SYSTEM_CURL)\n    if(CPR_ENABLE_SSL)\n        find_package(CURL COMPONENTS HTTP HTTPS)\n        if(CURL_FOUND)\n            message(STATUS "Curl ${CURL_VERSION_STRING} found on this system.")\n            # To be able to load certificates under Windows when using OpenSSL:\n            if(CURL_USE_OPENSSL AND WIN32 AND (NOT (CURL_VERSION_STRING VERSION_GREATER_EQUAL "7.71.0")))\n                message(FATAL_ERROR "Your system curl version (${CURL_VERSION_STRING}) is too old to support OpenSSL on Windows which requires curl >= 7.71.0. Update your curl version, use WinSSL, disable SSL or use the build in version of curl.")\n            endif()\n        else()\n            find_package(CURL COMPONENTS HTTP)\n            if(CURL_FOUND)\n                message(FATAL_ERROR "Curl found on this system but WITHOUT HTTPS/SSL support. Either disable SSL by setting CPR_ENABLE_SSL to OFF or use the build in version of curl by setting CPR_FORCE_USE_SYSTEM_CURL to OFF.")\n            else()\n                message(FATAL_ERROR "Curl not found on this system. To use the build in version set CPR_FORCE_USE_SYSTEM_CURL to OFF.")\n            endif()\n        endif()\n    else()\n        find_package(CURL COMPONENTS HTTP)\n        if(CURL_FOUND)\n            message(STATUS "Curl found on this system.")\n        else()\n            message(FATAL_ERROR "Curl not found on this system. To use the build in version set CPR_FORCE_USE_SYSTEM_CURL to OFF.")\n        endif()\n    endif()\nelse()\n    message(STATUS "Configuring build in curl...")\n\n    # ZLIB is optional for curl\n    # to disable it:\n    # * from command line:\n    #     -DCURL_ZLIB=OFF\n    # * from CMake script:\n    #     SET(CURL_ZLIB OFF CACHE STRING "" FORCE)\n    if (CURL_ZLIB OR CURL_ZLIB STREQUAL AUTO OR NOT DEFINED CACHE{CURL_ZLIB})\n        include(cmake/zlib_external.cmake)\n    endif()\n\n    # We only need HTTP (and HTTPS) support:\n    set(HTTP_ONLY ON CACHE INTERNAL "" FORCE)\n    set(BUILD_CURL_EXE OFF CACHE INTERNAL "" FORCE)\n    set(BUILD_TESTING OFF)\n\n    if (CPR_ENABLE_SSL)\n        set(SSL_ENABLED ON CACHE INTERNAL "" FORCE)\n        if(ANDROID)\n            set(CURL_CA_PATH "/system/etc/security/cacerts" CACHE INTERNAL "")\n        else()\n            set(CURL_CA_PATH "auto" CACHE INTERNAL "")\n        endif()\n\n        if(NOT DEFINED CURL_CA_BUNDLE)\n            set(CURL_CA_BUNDLE "auto" CACHE INTERNAL "")\n        endif()\n\n        if(SSL_BACKEND_USED STREQUAL "WinSSL")\n            set(CURL_USE_SCHANNEL ON CACHE INTERNAL "" FORCE)\n        endif()\n\n        if(SSL_BACKEND_USED STREQUAL "OpenSSL")\n            set(CURL_USE_OPENSSL ON CACHE INTERNAL "" FORCE)\n        endif()\n\n        if(SSL_BACKEND_USED STREQUAL "DarwinSSL")\n            set(CURL_USE_SECTRANSP ON CACHE INTERNAL "" FORCE)\n        endif()\n\n        if(SSL_BACKEND_USED STREQUAL "MbedTLS")\n            set(CURL_USE_MBEDTLS ON CACHE INTERNAL "" FORCE)\n        endif()\n\n        message(STATUS "Enabled curl SSL")\n    else()\n        set(SSL_ENABLED OFF CACHE INTERNAL "" FORCE)\n        set(CURL_CA_PATH "none" CACHE INTERNAL "" FORCE)\n        set(CURL_USE_SCHANNEL OFF CACHE INTERNAL "" FORCE)\n        set(CURL_USE_OPENSSL OFF CACHE INTERNAL "" FORCE)\n        set(CURL_USE_SECTRANSP OFF CACHE INTERNAL "" FORCE)\n        set(CURL_USE_MBEDTLS OFF CACHE INTERNAL "" FORCE)\n        message(STATUS "Disabled curl SSL")\n    endif()\n    # Disable linting for curl\n    clear_variable(DESTINATION CMAKE_CXX_CLANG_TIDY BACKUP CMAKE_CXX_CLANG_TIDY_BKP)\n\n    FetchContent_Declare(curl\n                         URL                    https://github.com/curl/curl/releases/download/curl-7_81_0/curl-7.81.0.tar.xz\n                         URL_HASH               SHA256=a067b688d1645183febc31309ec1f3cdce9213d02136b6a6de3d50f69c95a7d3 # the file hash for curl-7.81.0.tar.xz\n                         USES_TERMINAL_DOWNLOAD TRUE)   # <---- This is needed only for Ninja to show download progress\n    FetchContent_MakeAvailable(curl)\n\n    restore_variable(DESTINATION CMAKE_CXX_CLANG_TIDY BACKUP CMAKE_CXX_CLANG_TIDY_BKP)\n\n    # Group under the "external" project folder in IDEs such as Visual Studio.\n    if(BUILD_CURL_EXE)\n        set_property(TARGET curl PROPERTY FOLDER "external")\n    endif()\n        \n    set_property(TARGET libcurl PROPERTY FOLDER "external")\nendif()\n\n# GTest configuration\nif(CPR_BUILD_TESTS)\n    if(CPR_USE_SYSTEM_GTEST)\n        find_package(GTest)\n    endif()\n    if(NOT CPR_USE_SYSTEM_GTEST OR NOT GTEST_FOUND)\n        message(STATUS "Not using system gtest, using built-in googletest project instead.")\n        if(MSVC)\n            # By default, GTest compiles on Windows in CRT static linkage mode. We use this\n            # variable to force it into using the CRT in dynamic linkage (DLL), just as CPR\n            # does.\n            set(gtest_force_shared_crt ON CACHE BOOL "Force gtest to use the shared c runtime")\n        endif()\n\n        # Disable linting for google test\n        clear_variable(DESTINATION CMAKE_CXX_CLANG_TIDY BACKUP CMAKE_CXX_CLANG_TIDY_BKP)\n\n        FetchContent_Declare(googletest\n                             URL                    https://github.com/google/googletest/archive/release-1.11.0.tar.gz\n                             URL_HASH               SHA256=b4870bf121ff7795ba20d20bcdd8627b8e088f2d1dab299a031c1034eddc93d5 # the file hash for release-1.11.0.tar.gz\n                             USES_TERMINAL_DOWNLOAD TRUE)   # <---- This is needed only for Ninja to show download progress\n        FetchContent_MakeAvailable(googletest)\n\n        restore_variable(DESTINATION CMAKE_CXX_CLANG_TIDY BACKUP CMAKE_CXX_CLANG_TIDY_BKP)\n        \n        add_library(gtest_int INTERFACE)\n        target_link_libraries(gtest_int INTERFACE gtest)\n        target_include_directories(gtest_int INTERFACE ${googletest_SOURCE_DIR}/include)\n\n        add_library(GTest::GTest ALIAS gtest_int)\n       \n        # Group under the "tests/gtest" project folder in IDEs such as Visual Studio.\n    set_property(TARGET gtest PROPERTY FOLDER "tests/gtest")\n    set_property(TARGET gtest_main PROPERTY FOLDER "tests/gtest")\n    endif()\nendif()\n\n\n# Mongoose configuration\nif(CPR_BUILD_TESTS)\n    message(STATUS "Building mongoose project for test support.")\n\n    if(CPR_BUILD_TESTS_SSL)\n        if(NOT CPR_ENABLE_SSL)\n            message(FATAL_ERROR "OpenSSL is required to build SSL test but CPR_ENABLE_SSL is disabled. Either set CPR_ENABLE_SSL to ON or disable CPR_BUILD_TESTS_SSL.")\n        endif()\n\n        if(NOT(SSL_BACKEND_USED STREQUAL "OpenSSL"))\n            message(FATAL_ERROR "OpenSSL is required for SSL test, but it seams like OpenSSL is not being used as SSL backend. Either set CPR_BUILD_TESTS_SSL to OFF or set CPR_FORCE_OPENSSL_BACKEND to ON and try again.")\n        endif()\n\n        set(ENABLE_SSL_TESTS ON CACHE INTERNAL "")\n    else()\n        set(ENABLE_SSL_TESTS OFF CACHE INTERNAL "")\n    endif()\n\n    # Disable linting for mongoose\n    clear_variable(DESTINATION CMAKE_CXX_CLANG_TIDY BACKUP CMAKE_CXX_CLANG_TIDY_BKP)\n\n    FetchContent_Declare(mongoose \n                         URL                    https://github.com/cesanta/mongoose/archive/6.18.tar.gz\n                         URL_HASH               SHA256=f5c10346abc9c72f7cac7885d853ca064fb09aad57580433941a8fd7a3543769 # the hash for 6.18.tar.gz\n                         USES_TERMINAL_DOWNLOAD TRUE)   # <---- This is needed only for Ninja to show download progress\n    # We can not use FetchContent_MakeAvailable, since we need to patch mongoose to use CMake\n    if (NOT mongoose_POPULATED)\n        FetchContent_POPULATE(mongoose)\n\n        file(INSTALL cmake/mongoose.CMakeLists.txt DESTINATION ${mongoose_SOURCE_DIR})\n        file(RENAME ${mongoose_SOURCE_DIR}/mongoose.CMakeLists.txt ${mongoose_SOURCE_DIR}/CMakeLists.txt)\n        add_subdirectory(${mongoose_SOURCE_DIR} ${mongoose_BINARY_DIR})\n\n    endif()\n    # Group under the "external" project folder in IDEs such as Visual Studio.\n    set_property(TARGET mongoose PROPERTY FOLDER "external")\n    restore_variable(DESTINATION CMAKE_CXX_CLANG_TIDY BACKUP CMAKE_CXX_CLANG_TIDY_BKP)\nendif()\n\n\nadd_subdirectory(cpr)\nadd_subdirectory(include)\n\nif(CMAKE_PROJECT_NAME STREQUAL PROJECT_NAME AND CPR_BUILD_TESTS)\n    # Disable linting for test since they are currently not up to the standard\n    clear_variable(DESTINATION CMAKE_CXX_CLANG_TIDY BACKUP CMAKE_CXX_CLANG_TIDY_BKP)\n    enable_testing()\n    add_subdirectory(test)\n    restore_variable(DESTINATION CMAKE_CXX_CLANG_TIDY BACKUP CMAKE_CXX_CLANG_TIDY_BKP)\nendif()\n'}, 'traceback': None, 'children': [], 'date_done': '2025-01-31T03:50:23.827291', 'task_id': 'd841b3b0-9355-48da-814a-5999640a9df6'}
INFO:     127.0.0.1:48934 - "GET /api/summary/d841b3b0-9355-48da-814a-5999640a9df6 HTTP/1.1" 200 OK
[2025-01-31 11:51:01,124: DEBUG/SpawnProcess-1] Calling on_part_begin with no data
[2025-01-31 11:51:01,125: DEBUG/SpawnProcess-1] Calling on_header_field with data[42:61]
[2025-01-31 11:51:01,125: DEBUG/SpawnProcess-1] Calling on_header_value with data[63:117]
[2025-01-31 11:51:01,126: DEBUG/SpawnProcess-1] Calling on_header_end with no data
[2025-01-31 11:51:01,127: DEBUG/SpawnProcess-1] Calling on_header_field with data[119:131]
[2025-01-31 11:51:01,128: DEBUG/SpawnProcess-1] Calling on_header_value with data[133:148]
[2025-01-31 11:51:01,128: DEBUG/SpawnProcess-1] Calling on_header_end with no data
[2025-01-31 11:51:01,129: DEBUG/SpawnProcess-1] Calling on_headers_finished with no data
[2025-01-31 11:51:01,130: DEBUG/SpawnProcess-1] Calling on_part_data with data[152:6315]
[2025-01-31 11:51:01,131: DEBUG/SpawnProcess-1] Calling on_part_data with data[0:1]
[2025-01-31 11:51:01,131: DEBUG/SpawnProcess-1] Calling on_part_data with data[6316:6738]
[2025-01-31 11:51:01,132: DEBUG/SpawnProcess-1] Calling on_part_data with data[0:1]
[2025-01-31 11:51:01,133: DEBUG/SpawnProcess-1] Calling on_part_data with data[6739:7161]
[2025-01-31 11:51:01,134: DEBUG/SpawnProcess-1] Calling on_part_data with data[0:1]
[2025-01-31 11:51:01,134: DEBUG/SpawnProcess-1] Calling on_part_data with data[7162:13924]
[2025-01-31 11:51:01,135: DEBUG/SpawnProcess-1] Calling on_part_data with data[0:1]
[2025-01-31 11:51:01,135: DEBUG/SpawnProcess-1] Calling on_part_data with data[13925:14523]
[2025-01-31 11:51:01,136: DEBUG/SpawnProcess-1] Calling on_part_data with data[0:1]
[2025-01-31 11:51:01,137: DEBUG/SpawnProcess-1] Calling on_part_data with data[14524:15074]
[2025-01-31 11:51:01,137: DEBUG/SpawnProcess-1] Calling on_part_data with data[0:1]
[2025-01-31 11:51:01,138: DEBUG/SpawnProcess-1] Calling on_part_data with data[15075:15722]
[2025-01-31 11:51:01,139: DEBUG/SpawnProcess-1] Calling on_part_data with data[0:2]
[2025-01-31 11:51:01,139: DEBUG/SpawnProcess-1] Calling on_part_data with data[15724:16363]
[2025-01-31 11:51:01,139: DEBUG/SpawnProcess-1] Calling on_part_data with data[0:1]
[2025-01-31 11:51:01,140: DEBUG/SpawnProcess-1] Calling on_part_data with data[16364:16384]
[2025-01-31 11:51:01,142: DEBUG/SpawnProcess-1] Calling on_part_data with data[0:31386]
[2025-01-31 11:51:01,142: DEBUG/SpawnProcess-1] Calling on_part_data with data[0:1]
[2025-01-31 11:51:01,143: DEBUG/SpawnProcess-1] Calling on_part_data with data[31387:70746]
[2025-01-31 11:51:01,144: DEBUG/SpawnProcess-1] Calling on_part_data with data[0:1]
[2025-01-31 11:51:01,144: DEBUG/SpawnProcess-1] Calling on_part_data with data[70747:81904]
[2025-01-31 11:51:01,145: DEBUG/SpawnProcess-1] Calling on_part_data with data[0:1]
[2025-01-31 11:51:01,146: DEBUG/SpawnProcess-1] Calling on_part_data with data[81905:81920]
[2025-01-31 11:51:01,148: DEBUG/SpawnProcess-1] Calling on_part_data with data[0:76388]
[2025-01-31 11:51:01,149: DEBUG/SpawnProcess-1] Calling on_part_data with data[0:1]
[2025-01-31 11:51:01,150: DEBUG/SpawnProcess-1] Calling on_part_data with data[76389:176135]
[2025-01-31 11:51:01,151: DEBUG/SpawnProcess-1] Calling on_part_data with data[0:1]
[2025-01-31 11:51:01,152: DEBUG/SpawnProcess-1] Calling on_part_data with data[176136:262144]
[2025-01-31 11:51:01,153: DEBUG/SpawnProcess-1] Calling on_part_data with data[0:4967]
[2025-01-31 11:51:01,154: DEBUG/SpawnProcess-1] Calling on_part_data with data[0:1]
[2025-01-31 11:51:01,155: DEBUG/SpawnProcess-1] Calling on_part_data with data[4968:67498]
[2025-01-31 11:51:01,155: DEBUG/SpawnProcess-1] Calling on_part_data with data[0:1]
[2025-01-31 11:51:01,156: DEBUG/SpawnProcess-1] Calling on_part_data with data[67499:119573]
[2025-01-31 11:51:01,157: DEBUG/SpawnProcess-1] Calling on_part_data with data[0:1]
[2025-01-31 11:51:01,157: DEBUG/SpawnProcess-1] Calling on_part_data with data[119574:164124]
[2025-01-31 11:51:01,158: DEBUG/SpawnProcess-1] Calling on_part_data with data[0:1]
[2025-01-31 11:51:01,159: DEBUG/SpawnProcess-1] Calling on_part_data with data[164125:182422]
[2025-01-31 11:51:01,160: DEBUG/SpawnProcess-1] Calling on_part_data with data[0:1]
[2025-01-31 11:51:01,160: DEBUG/SpawnProcess-1] Calling on_part_data with data[182423:185687]
[2025-01-31 11:51:01,161: DEBUG/SpawnProcess-1] Calling on_part_data with data[0:1]
[2025-01-31 11:51:01,162: DEBUG/SpawnProcess-1] Calling on_part_data with data[185688:193501]
[2025-01-31 11:51:01,163: DEBUG/SpawnProcess-1] Calling on_part_data with data[0:1]
[2025-01-31 11:51:01,163: DEBUG/SpawnProcess-1] Calling on_part_data with data[193502:193924]
[2025-01-31 11:51:01,163: DEBUG/SpawnProcess-1] Calling on_part_data with data[0:1]
[2025-01-31 11:51:01,164: DEBUG/SpawnProcess-1] Calling on_part_data with data[193925:200907]
[2025-01-31 11:51:01,164: DEBUG/SpawnProcess-1] Calling on_part_data with data[0:1]
[2025-01-31 11:51:01,165: DEBUG/SpawnProcess-1] Calling on_part_data with data[200908:209255]
[2025-01-31 11:51:01,166: DEBUG/SpawnProcess-1] Calling on_part_data with data[0:1]
[2025-01-31 11:51:01,166: DEBUG/SpawnProcess-1] Calling on_part_data with data[209256:233901]
[2025-01-31 11:51:01,167: DEBUG/SpawnProcess-1] Calling on_part_data with data[0:1]
[2025-01-31 11:51:01,167: DEBUG/SpawnProcess-1] Calling on_part_data with data[233902:238647]
[2025-01-31 11:51:01,168: DEBUG/SpawnProcess-1] Calling on_part_data with data[0:1]
[2025-01-31 11:51:01,168: DEBUG/SpawnProcess-1] Calling on_part_data with data[238648:243759]
[2025-01-31 11:51:01,169: DEBUG/SpawnProcess-1] Calling on_part_data with data[0:1]
[2025-01-31 11:51:01,169: DEBUG/SpawnProcess-1] Calling on_part_data with data[243760:262132]
[2025-01-31 11:51:01,170: DEBUG/SpawnProcess-1] Calling on_part_data with data[0:2]
[2025-01-31 11:51:01,170: DEBUG/SpawnProcess-1] Calling on_part_data with data[262134:262143]
[2025-01-31 11:51:01,172: DEBUG/SpawnProcess-1] Calling on_part_data with data[0:1]
[2025-01-31 11:51:01,173: DEBUG/SpawnProcess-1] Calling on_part_data with data[0:2739]
[2025-01-31 11:51:01,173: DEBUG/SpawnProcess-1] Calling on_part_data with data[0:1]
[2025-01-31 11:51:01,174: DEBUG/SpawnProcess-1] Calling on_part_data with data[2740:15803]
[2025-01-31 11:51:01,175: DEBUG/SpawnProcess-1] Calling on_part_data with data[0:1]
[2025-01-31 11:51:01,176: DEBUG/SpawnProcess-1] Calling on_part_data with data[15804:20930]
[2025-01-31 11:51:01,176: DEBUG/SpawnProcess-1] Calling on_part_data with data[0:1]
[2025-01-31 11:51:01,177: DEBUG/SpawnProcess-1] Calling on_part_data with data[20931:31377]
[2025-01-31 11:51:01,178: DEBUG/SpawnProcess-1] Calling on_part_data with data[0:1]
[2025-01-31 11:51:01,178: DEBUG/SpawnProcess-1] Calling on_part_data with data[31378:57697]
[2025-01-31 11:51:01,179: DEBUG/SpawnProcess-1] Calling on_part_data with data[0:1]
[2025-01-31 11:51:01,179: DEBUG/SpawnProcess-1] Calling on_part_data with data[57698:73278]
[2025-01-31 11:51:01,180: DEBUG/SpawnProcess-1] Calling on_part_data with data[0:1]
[2025-01-31 11:51:01,181: DEBUG/SpawnProcess-1] Calling on_part_data with data[73279:93963]
[2025-01-31 11:51:01,182: DEBUG/SpawnProcess-1] Calling on_part_data with data[0:1]
[2025-01-31 11:51:01,183: DEBUG/SpawnProcess-1] Calling on_part_data with data[93964:157923]
[2025-01-31 11:51:01,183: DEBUG/SpawnProcess-1] Calling on_part_data with data[0:1]
[2025-01-31 11:51:01,184: DEBUG/SpawnProcess-1] Calling on_part_data with data[157924:187761]
[2025-01-31 11:51:01,184: DEBUG/SpawnProcess-1] Calling on_part_data with data[0:1]
[2025-01-31 11:51:01,185: DEBUG/SpawnProcess-1] Calling on_part_data with data[187762:214174]
[2025-01-31 11:51:01,186: DEBUG/SpawnProcess-1] Calling on_part_data with data[0:1]
[2025-01-31 11:51:01,187: DEBUG/SpawnProcess-1] Calling on_part_data with data[214175:218949]
[2025-01-31 11:51:01,187: DEBUG/SpawnProcess-1] Calling on_part_data with data[0:1]
[2025-01-31 11:51:01,188: DEBUG/SpawnProcess-1] Calling on_part_data with data[218950:229376]
[2025-01-31 11:51:01,189: DEBUG/SpawnProcess-1] Calling on_part_data with data[0:15190]
[2025-01-31 11:51:01,190: DEBUG/SpawnProcess-1] Calling on_part_data with data[0:2]
[2025-01-31 11:51:01,190: DEBUG/SpawnProcess-1] Calling on_part_data with data[15192:15749]
[2025-01-31 11:51:01,191: DEBUG/SpawnProcess-1] Calling on_part_data with data[0:1]
[2025-01-31 11:51:01,191: DEBUG/SpawnProcess-1] Calling on_part_data with data[15750:16265]
[2025-01-31 11:51:01,192: DEBUG/SpawnProcess-1] Calling on_part_data with data[0:2]
[2025-01-31 11:51:01,193: DEBUG/SpawnProcess-1] Calling on_part_data with data[16267:16272]
[2025-01-31 11:51:01,193: DEBUG/SpawnProcess-1] Calling on_part_data with data[0:2]
[2025-01-31 11:51:01,194: DEBUG/SpawnProcess-1] Calling on_part_end with no data
[2025-01-31 11:51:01,194: DEBUG/SpawnProcess-1] Calling on_end with no data
[2025-01-31 11:51:01,196: INFO/SpawnProcess-1] Received request - files: True, text: False, url: False
[2025-01-31 11:51:01,196: INFO/SpawnProcess-1] Creating new task with ID: 441a8496-35e1-4471-a277-e950c42fff3b
[2025-01-31 11:51:01,214: INFO/SpawnProcess-1] Saved file: uploads/441a8496-35e1-4471-a277-e950c42fff3b_c197-202305009.pdf
[2025-01-31 11:51:01,223: INFO/SpawnProcess-1] Created celery task with ID: 441a8496-35e1-4471-a277-e950c42fff3b
INFO:     127.0.0.1:48944 - "POST /api/summary HTTP/1.1" 200 OK
[2025-01-31 11:51:01,233: DEBUG/SpawnProcess-1] Task 441a8496-35e1-4471-a277-e950c42fff3b state: PENDING
[2025-01-31 11:51:01,234: DEBUG/SpawnProcess-1] Redis result for task 441a8496-35e1-4471-a277-e950c42fff3b: {'status': 'PENDING', 'result': None}
INFO:     127.0.0.1:48944 - "GET /api/summary/441a8496-35e1-4471-a277-e950c42fff3b HTTP/1.1" 200 OK
[2025-01-31 11:51:02,989: DEBUG/SpawnProcess-1] Task 441a8496-35e1-4471-a277-e950c42fff3b state: SUCCESS
[2025-01-31 11:51:02,992: DEBUG/SpawnProcess-1] Redis result for task 441a8496-35e1-4471-a277-e950c42fff3b: {'status': 'SUCCESS', 'result': {'status': 'success', 'summary': '文件 441a8496-35e1-4471-a277-e950c42fff3b_c197-202305009.pdf 内容:\n二十一世紀評論 \n31\n此項研究在這樣的猜想基礎上進行，即學習以及智能的任何其他特\n性的每一方面在原則上都能被精確描述，以致可使一台機器來模擬\n它。我們會嘗試尋求如何讓機器使用語言，形成抽象和概念，解決\n現在留待人類解決的問題，並提升自己。\n——1956年達特茅斯會議人工智能（AI）定義1\n2020至2022年，在新冠疫情肆虐全球的陰霾日子裏，人工智能（AI）創新\n的步伐完全沒有停止。美國人工智能研究公司OpenAI異軍突起：2020年4月\n發布神經網絡Jukebox2；5月發布語言模型GPT-33；6月開放人工智能應用\n程式介面（Application Programming Interface, API）；2021年1月發布連接文本和 \n圖像的神經網絡CLIP4；同月發布從文本創建圖像的神經網絡DALL • E5；\n2022年11月正式推出了對話互動式的聊天機器人程式ChatGPT6。相比於\nGPT-3，ChatGPT引入了基於人類回饋的強化學習（Reinforcement Learning from  \nHuman Feedback, RLHF）技術以及獎勵機制7。\nGPT-3的發布是人類科技史上的里程碑事件，在短短幾個月席捲全球，速\n度超過人類最狂野的想像。GPT-3證明了一個具有高水平複雜結構和大量參 \n數的人工智能大模型（foundation model，又稱「基礎模型」）可以實現深度學習\n（deep learning）。此後，大模型概念得到前所未有的關注和討論。但是，關於\n「大模型」的定義，對其內涵的理解和詮釋卻莫衷一是，「橫看成嶺側成峰，遠\n近高低各不同」。\n儘管如此，並不妨礙人們形成了關於大模型的基本共識：大模型是大語\n言模型（Large Language Model, LLM），也是多模態模型（multimodal model）。 \nGPT是大模型的一種形態，G代表生成性的（generative），P代表經過預訓 \n人工智能大模型\n——當代歷史的標誌性事件及其意義\n二十一世紀雙月刊\u30002023年6月號\u3000總第一九七期\n\n32 \n二十一世紀評論\n練（pre-trained），T代表變換器（transformer）8。它引發了人工智能生成內容 \n（Artificial Intelligence Generated Content, AIGC）技術的質變。大模型是人工智\n能賴以生存和發展的基礎。現在，與其說人類開始進入人工智能時代，不如\n說人類進入的是大模型時代。我們不僅目睹，也身在其中體驗了生成式大模\n型如何開始生成一個全新時代。\n本文通過七個部分，分別說明大模型的定義、人工智能的歷史、大模型\n的基本特徵、Transformer結構、GPU和能源、知識革命、「人的工具化」及大\n模型在其中的作用，有助於進一步解讀大模型對於人類科技發展的重要意涵。\n一\u3000何謂大模型？\n人工智能的模型，與通常的模型一樣，是以數學和統計學作為演算法基\n礎的，可以用來描述一個系統或者一個數據集。在機器學習（machine learning） \n中，模型是核心概念。模型通常是一個函數或者一組函數，以線性函數、非\n線性函數、決策樹、神經網絡等各種形式呈現。模型的本質就是對這個／組函\n數映射的描述和抽象，通過對模型進行訓練和優化，能夠得到更加準確和有\n效的函數映射。模型的目的是為了從數據中找出一些規律和模式，達到預測\n未來的結果。模型的複雜度可以理解為模型所包含的參數數量。一個模型的\n參數數量愈多，通常意味着該模型可以處理更複雜、更豐富的信息，具備更高\n的準確性和表現力。大模型一般用於解決複雜的自然語言處理（Natural Language  \nProcessing, NLP）、電腦視覺和語音辨識等任務。這些任務需要處理大量的輸\n入數據，並從中提取複雜的特徵和模式。通過使用大模型，深度學習演算法\n就能更好地處理這些任務，提高模型的準確性和性能。\n大模型的「大」，是指模型參數至少達到1億以上。但是這個標準一直在升\n級，目前很可能已經有了萬億參數以上的模型。GPT-3大約的參數規模是\n1,750億。除了大模型之外，還有所謂的「超大模型」。超大模型是比大模型更\n大、更複雜的人工神經網絡（Artificial Neural Network, ANN）模型，通常擁有\n數萬億到數千萬億參數。超大模型一般被用於解決更為複雜的任務，如自然\n語言處理中的問答和機器翻譯、電腦視覺中的目標檢測和圖像生成等。這些\n任務需要處理極其複雜的輸入數據和高維度的特徵，超大模型可以在這些數\n據中提取出更深層次的特徵和模式，提高模型的準確性和性能，所以，超大\n模型的訓練和調整需要極其巨大的計算資源和大量數據、更加複雜的演算法\n和技術、大規模的投入和協作。\n大模型和超大模型的主要區別在於模型參數數量的多寡、計算資源的需\n求和性能表現。伴隨大模型參數規模的膨脹，大模型和超大模型的界限正在\n消失。現在包括GPT-4在內的代表性大模型，其實就是原本的超大模型。或\n者說，原本的超大模型，就是現在的大模型。\n\n二十一世紀評論 \n33\n如前所述，大模型可以定義為大語言模型，即具有大規模參數和複雜網\n絡結構的語言模型。與傳統語言模型（如生成性模型、分析性模型、辨識性 \n模型）不同9，大語言模型通過在大規模語料庫上進行訓練來學習語言的統計\n性規律，在訓練時通常通過大量的文本數據進行自監督學習bk，從而能夠自\n動學習到語法、句法、語義等多層次的語言規律。\n如果從人工智能的生成角度定義大模型，與傳統的機器學習演算法不同， \n生成式大模型可以根據文本提示生成代碼，還可以解釋代碼，甚至在某些情\n況下調試代碼。在這樣的過程中，不僅實現文本、圖像、音訊、視頻的生成， \n構建多模態，而且還在更為廣泛的領域生成新的設計、新的知識和思想，甚\n至廣義的藝術和科學的再創造。\n近幾年，比較有影響的大模型主要來自Google、Meta和OpenAI。除了\nOpenAI的GPT之外，2018至2023年Google先後發布對話程式語言模型LaMDA、 \nBERT和PaLM-Ebl。2023年，Facebook的母公司Meta推出大語言模型LLaMA， \n以及在Meta AI博客上免費公開大語言模型OPT-175Bbm。在中國，大模型主\n要代表是百度的「文心一言」和華為的「盤古」。這些模型的共同特徵是：需要\n在大規模數據集上進行訓練，基於大量的計算資源進行優化和調整。因為大\n模型的出現和發展所顯示的湧現性、擴展性和複合性，長期以來人們討論的\n所謂「弱人工智能」、「強人工智能」和「超人工智能」的界限不復存在，這樣劃\n分的意義也自然消失bn。\n二\u3000大模型是人工智能歷史的突變和湧現\n如果從1956年美國達特茅斯學院（Dartmouth College）的人工智能會議算\n起，還有三年，人工智能歷史就踏入七十年。該會議引申出人工智能三個基\n本派別：一、符號學派（Symbolism），又稱為邏輯主義、心理學派或電腦學\n派。該學派主張通過電腦符號操作來類比人的認知過程和大腦抽象邏輯思維， \n實現人工智能。符號學派主要集中在人類推理、規劃、知識表示等高級智能\n領域。二、聯結學派（Connectionism），又稱為仿生學派或生理學派。該學派\n強調對人類大腦的直接類比，認為神經網絡和神經網絡間的連接機制與學習\n演算法能夠產生人工智能。學習和訓練是需要有內容的，數據就是機器學習、 \n訓練的內容。聯結學派的技術性突破包括感知機（下詳）、人工神經網絡、深\n度學習。三、行為學派（Actionism），思想來源是進化論和控制論。其原理為\n控制論以及感知—動作型控制系統。該學派認為行為是個體用於適應環境變\n化的各種身體反應的組合，它的理論目標在於預見和控制行為bo。\n比較上述三個人工智能派別：符號學派依據的是抽象思維，注重數學可\n解釋性；聯結學派則是形象思維，偏向於仿人腦模型；行為學派是感知思\n維，傾向身體和行為模擬。從共同性方面來說，這三個派別都以演算法、算\n\n34 \n二十一世紀評論\n力和數據作為核心要素。但是在相當長的時間裏，符號學派主張的基於推理\n和邏輯的人工智能路線處於主流地位。不過，電腦只能處理符號，不可能具\n有人類最為複雜的感知。二十世紀80年代末，符號學派開始走向式微。之後\n的人工智能編年史，有三個重要的里程碑。\n第一個里程碑：機器學習。機器學習理論的提出，可以追溯到圖靈（Alan \nTuring）寫於1950年的一篇論文〈電腦機器與智慧〉（“Computing Machinery and \nIntelligence”）和圖靈測試（The Turing test）bp。1952年，在國際商業機器公司\n（IBM）工作的塞繆爾（Arthur L. Samuel）開發了一個西洋棋的程式。該程式能\n夠通過棋子的位置學習一個隱式模型，為下一步棋提供比較好的走法。塞繆\n爾用這個程式駁倒了機器無法超越書面代碼、並像人類一樣學習的論斷。他\n創造並定義了「機器學習」bq。\n機器學習是一個讓電腦不用顯示程式設計就能獲得能力的研究領域。\n1980年，美國卡內基梅隆大學（Carnegie Mellon University）召開了第一屆機器\n學習國際研討會，標誌着機器學習研究已在全世界興起。此後，機器學習開\n始得到大量應用。1986年，三十多位人工智能專家共同撰寫的《機器學習：一\n項人工智能方案》（Machine Learning: An Artificial Intelligence Approach）文集\n第二卷出版br，顯示出機器學習突飛猛進的發展趨勢bs。二十世紀80年代中\n葉是機器學習的最新階段，機器學習已成為新的學科，它綜合應用了心理學、 \n生物學、神經生理學、數學、自動化和電腦科學等，形成理論基礎。1995年， \n瓦普尼克（Vladimir N. Vapnik）和科茨（Corinna Cortes）提出的支持向量機（Support  \nVector Machine, SVM，又稱「支持向量網絡」），實現機器學習領域最重要的突\n破，具有非常強的理論論證和實證結果。\n機器學習有別於人類學習，二者的應用範圍和知識結構有所不同：機器\n學習是基於對數據和規則的處理和推理，主要應用於數據分析、模式識別、\n自然語言處理等領域；而人類學習是一種有目的、有意識、逐步積累的過\n程。總之，機器學習是一種基於演算法和模型的自動化過程，並分為監督學\n習和自監督學習兩種。\n第二個里程碑：深度學習。深度學習是機器學習的一個分支。所謂「深\n度」是指神經網絡中隱藏層（位於輸入和輸出之間的層）的數量。傳統的神經網\n絡只包含兩至三個隱藏層，而深度神經網絡可以有多達150個隱藏層，提供了\n大規模的學習能力。隨着大數據和深度學習爆發並得以高速發展，最終成就\n了深度學習理論和實踐。2006年，辛頓（Geoffrey E. Hinton）正式提出「深度置\n信網絡」（Deep Belief Nets/Deep Belief Network, DBN）概念bt，那一年成為了\n「深度學習元年」。在辛頓深度學習理論的背後，是堅信如果不了解大腦，就\n永遠無法理解人類的認識。人腦必須用自然語言進行溝通，而只有1.5公斤重\n的大腦，大約有860億個神經元（通常稱為「灰質」）與數萬億個突觸相連。人\n們可以把神經元看作是接收數據的中央處理器（Central Processing Unit, CPU）。 \n所謂「深度學習」可以伴隨着突觸的增強或減弱而發生，即在一個擁有大量神\n\n二十一世紀評論 \n35\n經元的大型神經網絡中，計算節點和它們之間的連接，僅通過改變連接的強\n度，從數據中學習。辛頓認為，實現人工智能的進步需要通過生物學途徑，\n或者通過神經網絡途徑替代模擬硬件途徑，形成基於100萬億個神經元之間的\n連接變化的深度學習。\n深度學習主要涉及三類方法：一、基於卷積運算的神經網絡系統，卷積\n神經網絡（Convolutional Neural Network, CNN）是一類包含卷積運算且具有深\n度結構的前饋神經網絡，是深度學習的代表演算法之一。二、基於多層神經\n元的自編碼神經網絡，包括自編碼（auto encoder）和近年來受到廣泛關注的稀\n疏編碼（sparse coding）兩類。三、以多層自編碼神經網絡的方式進行預訓練，\n進而結合鑒別信息進一步優化神經網絡權值的深度置信網絡。通過多層處\n理，逐漸將初始的「低層」特徵表示轉化為「高層」特徵表示後，用簡單模型即\n可完成複雜的分類等學習任務。\n深度學習是建立在人工神經網絡理論和機器學習理論上的科學，它使用\n建立在複雜的網絡結構上的多處理層，結合非線性轉換方法，對複雜的數據\n模型進行抽象，得以識別圖像、聲音和文本。在深度學習的歷史上，卷積神\n經網絡和循環神經網絡（Recurrent Neural Network, RNN）曾經是兩種經典模\n型。在循環神經網絡中，節點之間的連接可以形成一個循環，允許一些節點\n的輸出影響到同一節點的後續輸入，因此能夠表現出時間上的動態行為。\n2012年，辛頓和克里澤夫斯基（Alex Krizhevsky）設計的AlexNet神經網絡\n模型在ImageNet競賽中實現圖像識別和分類，成為新一輪人工智能發展的起\n點。這類系統可以處理大量數據，發現人類通常無法發現的關係和模式。\n2016年人工智能機器人AlphaGO戰勝韓國職業圍棋棋手李世石，這是深度學\n習的經典範例。\n第三個里程碑：人工智能生成內容大模型。2018年10月，Google發布\nBERT模型是代表性事件。該模型是一種雙向的基於Transformer的自監督語\n言模型，通過大規模預訓練無標註數據來學習通用的語言表示，從而能夠在\n多種下游任務，如專名識別、詞性標記和問題回答中進行微調。利用大型文\n本語料庫BookCorpus和英文維基百科裏純文字的部分，無須標註數據，用設\n計的兩個自監督任務來進行訓練，訓練完成的模型通過微調在十一個下游任\n務上實現最佳性能。\n因為BERT模型，掀起了預訓練模型的研究熱潮，從2018年開始大模型\n迅速流行，預訓練語言模型 （Pre-trained Language Model, PLM）及其「預訓練—\n微調」方法已成為自然語言處理任務的主流範式。大模型利用大規模無標註數\n據通過自監督學習進行預訓練，再利用下游任務的有標註數據進行自監督學\n習以微調模型參數，實現下游任務的適配ck。\n如前所述，大模型的訓練需要大量的計算資源和數據，OpenAI使用了 \n數萬台CPU和圖形處理器（Graphics Processing Unit, GPU），並利用了多種技\n術，如自監督學習和增量訓練等，對模型進行了優化和調整。2018至2023年，\n\n36 \n二十一世紀評論\nOpenAI實現大模型從GPT-1到GPT-4的五次迭代，同時開放了應用程式介\n面，使得開發者可以利用大模型進行自然語言處理的應用開發。\n總之，大模型是基於包括數學、統計學、電腦科學、物理學、工程學、\n神經學、語言學、哲學、人工智能學融合基礎上的一次突變，並導致了一種\n「湧現」（emergence）。大模型是一種革命。在模型尚未達到某個臨界點之前，\n根本無法解決問題，性能也不會比隨機好。但是，當大模型突破某個臨界點\n之後，性能會發生愈來愈明顯的改善，形成爆發性的湧現能力。如論者所言： \n「許多新的能力在中小模型上線性放大規模都得不到線性的增長，模型規模必\n須要指數級增長超過某個臨界點，新技能才會突飛猛進。」cl\n更為重要的是，大模型賦予人工智能以思維能力——一種與人類近似，\n又很不相同的思維能力。前述AlphaGo戰勝李世石的世紀級圍棋大賽，證明\n了人工智能思維的優勢。\n三\u3000大模型的基本特徵\n大模型的基本特徵可以總結為：以人工神經網絡作為基礎；為神經網絡提\n供更好的預訓練方法並促進規模化，能顯著降低人工智能工程化門檻；具有理\n解自然語言的能力和模式；已經形成「思維鏈」；需要向量數據庫的支援；具有\n不斷成長的泛化功能，並且被植入了控制論的基於人類回饋的強化學習機制。\n大模型以人工神經網絡作為基礎。1943年，心理學家麥卡洛克（Warren S. \nMcCulloch）和數理邏輯學家皮茨（Walter H. Pitts, Jr.）建立了第一個神經網絡模\n型，即M-P模型（又稱「麥卡洛克—皮茨模型」或「MCP模型」）。該模型是對生\n物神經元結構的一種模仿，將神經元的樹突、細胞體等接收信號定義為輸入\n值x，突觸發出的信號定義為輸出值y。M-P模型奠定了支援邏輯運算的神經\n網絡基礎。1958年，電腦專家羅森布拉特（Frank Rosenblatt）基於M-P模型發\n明了包括輸入層、輸出層和隱藏層的感知機（perceptron）。神經網絡的隱藏層\n最能代表輸入數據類型特徵（圖1）。從本質上講，這是第一台使用模擬人類思\n維過程的神經網絡的新型電腦。\n以OpenAI為代表的團隊，為了讓具有多層表示的神經網絡學會複雜事\n物，創造了一個初始化網絡的方法，即預訓練。實際上，生成式大模型為神\n經網絡提供了更好的預訓練方法。現在的大模型都是以人工神經網絡作為基\n礎的演算法數學模型，其基本原理依然是羅森布拉特的感知機。這種人工智\n能網絡依靠系統的複雜程度，通過調整內部大量節點之間相互連接的關係，\n從而達到處理信息的目的。\n大模型生成內容的前提是大規模的文本數據輸入，並在海量的通用數據\n上進行預訓練。通過預訓練不斷調整和優化模型參數，使得模型的預測結果\n盡可能接近實際結果。預訓練中使用的大量文本數據包括維基百科、網頁文\n\n二十一世紀評論 \n37\n本、書籍、新聞文章等，用於訓練模型的語言模型部分。此外，還可以根據\n應用場景和需求，調用其他外部數據資源，包括知識庫、情感詞典、關鍵詞\n提取、實體識別等。在預訓練的過程中，大模型不是依賴於人為編寫的語法\n規則或句法規則，而是通過學習到的語言模式和統計性規律，以生成更加符\n合特定需求和目標的文本輸出。\n預訓練促進了規模化。所謂的「規模化」是指用於訓練模型的大量計算，\n最終轉化為規模愈來愈大的模型，具有愈來愈多的參數。在預訓練過程中，\n大模型形成理解上下文的學習能力。或者說，伴隨上下文學習的出現，人們\n可以直接使用預訓練模型。大模型通過大量語料庫訓練，根據輸入文本和上\n下文生成合適的文本輸出，學習詞彙、句法結構、語法規則等多層次的語言\n知識；通過對大量樣本進行學習，更多的計算資源的投入（包括正確和錯誤的\n文本樣本），捕捉到語法和句法的統計性規律，形成一個詞或字元的概率的預\n測能力，進而根據不同樣本的預測錯誤程度調整參數，處理複雜的語境，最\n終逐漸優化生成的文本。例如，ChatGPT會根據之前與使用者交互的上下文和\n當前的生成狀態，選擇最有可能的下一個詞或短語。\n「預訓練—微調」方法能顯著降低人工智能工程化門檻。預訓練模型在海\n量數據的學習訓練後具有良好的泛化性（下詳），使得細分場景的應用廠商能\n夠基於大模型，通過零樣本、小樣本學習來獲得顯著的效果。因此，人工智\n能有望構建成統一的智慧底座，以賦能各行各業。生成式大模型不會止步於\n簡單的內容生成，而會逐步達到更高的人工智能，得以預測、決策、探索。\n針對大量數據訓練出來的預訓練模型，後期採用業務相關數據進一步訓練原\n先模型的相關部分，給出額外的指令或者標註數據集來提升模型的性能，通\n過微調從而得到準確度更高的模型。\n大模型具有理解自然語言的能力和模式。自然語言如漢語、英語及其文\n字，具有複雜性和多樣性，且伴隨文化演變而進化；通過表達含義，實現人\n隱藏層\n輸\n入\n層\n輸\n出\n層\n圖1\u3000神經網絡的層級關係：由輸入到輸出\n圖片來源：筆者改製自Moonzarin Reza, “Galaxy Morphology Classification Using Automated \nMachine Learning”, Astronomy and Computing, vol. 37 (October 2021), https://doi.org/ \n10.1016/j.ascom.2021.100492。\n\n38 \n二十一世紀評論\n類溝通和交流，推動人類思維發展。對自然語言的理解，首先要理解文本的\n特徵。在大模型研究的早期階段，主要集中在自然語言處理領域，形成從簡\n單的文本問答、文本創作到符號式語言的推理能力。之後大模型發生程式設\n計語言的變化，有助於更多人直接參與大模型用於問答的自然語言交互和程\n式設計模式，經過形式極簡的文本輸入，利用自然語言表達的豐富性，形成\n自然語言與模型的互動。上述的BERT、GPT等一系列代表性模型，不同於基\n於語法規則、句法規則的傳統語言模型；這些大語言模型基於統計語言學的\n思想，在大量文本數據上進行自監督學習，利用自然語言中的統計性規律（涉\n及貝葉斯原理[Bayes theorem]和馬爾可夫鏈[Markov chain]等數學工具，以及\nN元[n-gram]語言模型cm），通過對大量語法和句法樣本學習，捕捉到相關規\n則並進行推斷，對各種不同形式的語言表達具有一定的容忍性、適應性和靈\n活性，從而生成具有語法和語義合理性的文本。\n大模型已經形成「思維鏈」（Chain-of-Thought, CoT）。思維鏈是重要的微\n調技術手段，其本質是一個多步推理的過程。通過讓大語言模型將一個問題\n拆解為多個步驟，一步一步分析，逐步得出正確答案。我們還可以這樣理解： \n思維鏈相當於大模型中的數據，人工智能以思維鏈為數據，然後再進行微調和\n回饋，從而形成人工智能能力。在電腦語言中，有所謂「第四範式」（Fourth \nNormal Form, 4NF）概念，有助於理解思維鏈的功能，也有助於大模型更加結\n構化和規範化，減少數據信息冗餘和碎片化等弊病，提高大模型的效率。\n大模型需要向量數據庫的支援。向量是大模型的數據存儲的基本單位。\n雖然大模型呈現端到端、文本輸入輸出的形式，但是實際接收和學習的數據\n並不是傳統文本，因為文本本身數據維度太高、學習過於低效，所以需要向\n量化的文本。「所謂向量化的文本，就是模型對自然語言的壓縮和總結」。向\n量是人工智能理解世界的通用數據形式，大模型依賴向量數據庫，其即時性\n對分散式運算的要求很高，隨着數據的變化即時更新，以保障向量的高效存\n儲和搜索cn。\n大模型具有不斷成長的泛化（generalization）功能。大模型泛化是指大模型\n可以應用（泛化）到其他場景，泛化能力是模型的核心。大語言模型通過大量\n的數據訓練，掌握語言中的潛在模式和規律，在面對新的、未見過的語言表\n達時具有一定的泛化能力。在新的場景下，針對新的輸入信息，大模型就能\n做出判斷和預測。而基於語法規則、句法規則的傳統語言模型通常需要人為\n編寫和維護規則，對於未見過的語言表達可能表現較差。針對泛化誤差，大\n模型通常採用遷移學習、微調等手段，在數學上權衡偏差和方差。大語言模\n型廣泛應用於自然語言處理領域的多個任務，如語言生成、文本分類、情感\n分析、機器翻譯等。說到底，大模型的泛化就是指其通用性，最終需要突破\n泛化過程的局限性。但是，實現通用大模型，還有很長的路。\n大模型植入了控制論的基於人類回饋的強化學習機制。回饋是控制論中\n的基本概念，是指一個系統把信息輸送出去，又把其作用結果返回，並對信\n\n二十一世紀評論 \n39\n息的再輸出產生影響，起到控制和調節作用的過程。大模型構建人類回饋數\n據集，訓練一個激勵模型，模仿人類偏好對結果打分，通過從外部獲得激勵\n來校正學習方向，從而獲得一種自適應（self-adaptive）的學習能力。\n四\u3000大模型和Transformer\n如果說神經網絡是大模型的「大腦」，那麼Transformer就是大模型的「心\n臟」。2017年6月，Google團隊的瓦斯瓦尼（Ashish Vaswani）等人發表論文〈注\n意力足矣〉（“Attention Is All You Need”），系統提出了Transformer的原理、\n構建和大模型演算法。此文的開創性思想，顛覆了以往將序列建模和循環神\n經網絡畫等號的思路，開啟了預訓練模型的時代co。\nTransformer是一種基於「注意力機制」（attention mechanism）的深度神經\n網絡，可以高效並行處理序列數據，與人的大腦非常近似。Transformer的基\n本特徵如下：（1）由編碼組件（encoder）和解碼組件（decoder）兩個部分組成。\n（2）採用神經網絡處理序列數據。神經網絡的工作是將一種類型的數據轉換 \n為另一種類型的數據；在訓練期間，神經網絡的隱藏層以最能代表輸入數據\n類型特徵的方式調整其參數，並將其映射到輸出。（3）擁有的訓練數據和參數\n愈多，它就愈有能力在較長文本序列中保持連貫性和一致性。（4）標記和嵌\n入。輸入文本必須經過處理並轉換為統一格式，然後才能輸入到Transformer。 \n（5）實現並行處理整個序列，從而將深度學習模型擴展到前所未有的速度和 \n容量。（6）引入了注意力機制，在正向和反向的非常長的文本序列中跟蹤單 \n詞之間的關係，包括自注意力（self-attention）機制和多頭注意力（multi-head \nattention）機制。Transformer的多頭注意力機制中有多個自注意力機制，可以\n捕獲單詞之間多種維度上的相關系數注意力評分（attention score），摒棄了卷\n積神經網絡和循環神經網絡。（7）訓練和回饋。在訓練期間，Transformer提供\n了規模非常大的配對示例語料庫（例如英語句子及其相應的法語翻譯）。編碼\n器模組接收並處理完整的輸入字串，嘗試建立編碼的注意向量和預期結果之\n間的映射。\n在Transformer之前，發揮近似功能的是循環神經網絡或卷積神經網絡。\nTransformer起初主要應用於自然語言處理，但漸漸地，它們在幾乎所有的領\n域都發揮了作用。通用性一直是Transformer最大的優勢，包括圖像、視頻、\n音訊等多種領域的模型都需要使用Transformer。\n總之，Transformer是一種非常高效、易於擴展、並行化的神經網絡架\n構，其核心是基於注意力機制的技術，可以建立起輸入和輸出數據的不同組\n成部分之間的依賴關係，具有品質更優、更強的並行性和訓練時間顯著減少\n的優勢。Transformer現在被廣泛應用於自然語言處理的各個領域，如GPT、\nBERT等，都是基於Transformer模型。\n\n40 \n二十一世紀評論\n五\u3000大模型、GPU和能源\n任何類型的大模型都是由複雜構造支援的，包括硬件基礎設施層、軟件\n基礎設施層、模型MaaS（Mobility as a Service，即「交通行動服務」）層和應用\n層（圖2）。在這一結構中，GPU就是硬件基礎設施層的核心所在。隨着人工智\n能時代的到來，人工智能演算法效率已經超越了摩爾定律（Moore’s Law）。 \n摩爾定律的內容為：積體電路上可容納的電晶體數目，約每隔兩年便會增加\n一倍。二十一世紀以來，摩爾定律面臨新的生態：功耗（包括開關功耗）、記\n憶體極限，以及算力瓶頸等「技術節點」。摩爾定律逼近物理極限，無法迴 \n避量子力學的限制。在其限制下只有三項選擇：延緩摩爾，擴展摩爾，超 \n越摩爾。延緩摩爾定律即突破技術難題，延長該定律的適用時間；擴展摩爾\n定律即將該定律推廣至諸如量子電腦一類新興計算平台；超越摩爾定律即 \n另闢蹊徑，通過技術組合方案如「芯粒」（chiplet），實際達到最新的計算能力\n要求。\n應用層\n端到端應用、大模型應用、企業服務\n模型MaaS層\n開源大模型、閉源大模型\n軟件基礎設施層\n分布式深度學習框架、數據工具、模型庫社區\n硬件基礎設施層\n雲服務和GPU\n圖2\u3000大模型產業的多層結構\n圖片來源：筆者繪製。\nGPU具有數量眾多的運算單元，採用極簡的流水線進行設計，適合計算\n密集、易於並行的程式，特別是具備圖形渲染和通用計算的天然優勢。大模\n型的訓練和推理對GPU提出了更高的要求：更高的計算能力、更大的顯存容\n量、更快的顯存頻寬、更高效的集群通信能力、低延遲和低成本的推理。\nGPU可以通過異構計算（heterogenous computing）提供端到端的深度學習資\n源，縮短訓練所需的環境部署時間。總之，GPU的高性能計算推動了大模型\n\n二十一世紀評論 \n41\n的發展，大模型不斷對GPU提出迭代要求。例如，微軟（Microsoft）為OpenAI\n開發的用於大模型訓練的超級電腦是一個單一系統，伺服器擁有超過28.5萬\n個CPU內核、1萬個GPU和400Gbps的網絡連接。\n大模型的演變將加速對能源的需求。根據國際數據公司（IDC）預測，到\n2025年，全球數據量將達到175ZB，而且近90%的數據都是非結構化的。這\n些數據需要大量的計算能力才能被分析和處理。同時，隨着人工智能演算法\n不斷升級和發展，它們的複雜性和計算量也在不斷增加。據估計，目前人工\n智能的能源消耗佔全球能源消耗約3%，而據此推斷，到2025年，人工智能將\n消耗15%的全球電力供應。除了硬件開發所必須投入的「固定碳成本」以外，\n對於人工智能日常環境的維護投入也不容小覷。所以，人工智能的快速發展\n將對能源消耗和環境產生巨大的影響cp。\n人工智能的快速發展和應用帶來了能源消耗和環境問題，需要在技術和\n政策上尋求解決方案。在這個過程中，需尋求可持續的能源供應，以減少對\n傳統能源的依賴，開發在非常低功耗的芯片上運行的高效大模型。\n六\u3000大模型和知識革命\n一般來說，知識結構類似金字塔，包括了數據、信息、知識和智慧四個\n層次（圖3）。大模型具有極為寬泛的溢出效應。其中最為重要的是引發前所未\n有的學習革命和知識革命。\n智慧\n知識\n信息\n數據\n圖3\u3000由數據到智慧的金字塔\n圖片來源：筆者繪製。\n基於大數據與Transformer的大模型，實現了對知識體系的一系列改變：\n（1）改變知識生產的主體。即從人類壟斷知識生成轉變為人工智能生產知識，\n以及人類和人工智能混合生產知識。（2）改變知識譜系。從本質上來看，知識\n圖譜是語義網絡的知識庫；從實際應用的角度來看，可以將知識圖譜簡化理\n解成多關係圖。我們通常用圖裏的節點來代表實體，用連接節點的直線來代\n表兩個節點之間的關係。實體指的是現實世界的事物，兩點連線表示不同實\n體之間的某種聯繫（圖4）。不同於以往的知識譜系模型，如本體或知識地圖\n\n42 \n二十一世紀評論\n等，知識圖譜包含大量結構化的實體知識，具備更好的組織、管理和理解互\n聯網信息的能力，與提升大模型的訓練效果息息相關，表現出大模型時代知\n識供給的特徵。（3）改變知識的維度。知識可分為簡單知識和複雜知識、獨有\n知識和共有知識、具體知識和抽象知識、顯性知識和隱性知識等。二十世紀\n50年代，世界著名的科學哲學大師波蘭尼（Michael Polanyi）發現了知識的隱性\n維度，而人工智能易於把握知識的隱性維度。（4）改變知識獲取途徑。大模型\n正在引領教育革命，人們熟悉的搜尋引擎正在由啟發式的聊天機器人逐步取\n代。（5）改變推理和判斷方式。人類的常識基於推理和判斷，而機器常識則是\n基於邏輯和演算法；人類可以根據自己的經驗和判斷力做出決策，而機器則\n需要依賴程式和演算法。（6）改變知識創新方式和加速知識更新速度。不僅知\n識更新可以通過人工智能實現內容生成，而且大模型具有不斷生成新知識的\n天然優勢；人類知識處理的範式將發生轉換，人類知識的邊界有機會更快速\n地擴展。（7）改變知識處理方式。人類對知識的處理有六個層次：記憶、理\n解、應用、分析、評價和創造。大模型在這六個層次的知識處理中，都能發\n揮一定的作用，為人類大腦提供輔助。\n圖4\u3000知識圖譜示例\n實體\n一\n實體\n二\n關係\n圖片來源：筆者繪製。\n簡言之，如果大模型與外部知識源（例如搜尋引擎）和工具（例如程式設計\n語言）結合，將豐富知識體系和提高獲取知識的效率。萬物皆可人工智能化，\n大模型將引發知識革命，形成人類自然智慧和人工智能智慧並存的局面。\n知識需要學習。基於赫布理論（Hebbian theory）的學習方法被稱為「赫布型 \n學習」。赫布理論又稱「赫布定律」\n（Hebb’s rule）、「赫布假說」\n（Hebb’s postulate）、 \n「細胞結集理論」\n（cell assembly theory）等，是一個神經科學理論，由赫布（Donald  \nO. Hebb）於1949年提出，描述了在學習過程中大腦的神經元所發生的變化，\n從而形成記憶印痕cq。赫布理論描述了突觸可塑性的基本原理，即突觸前神\n經元向突觸後神經元的持續重複的刺激，可以導致突觸傳遞效能的增加。以\n深度學習為核心的大模型的重要特徵就是以人工神經網絡作為基礎。所以，\n大模型是充分實踐赫布理論的重要工具。\n1995年，美國哈佛大學心理學家珀金斯（David N. Perkins）提出「真智力」\n（true intelligence），並提出智商包括三種主要成份或維度：（1）神經智力（neural \nintelligence），具有「非用即失」\n（use it or lose it）的特點。（2）經驗智力（experiential\n\n二十一世紀評論 \n43\nintelligence），是指個人積累的不同領域的知識和經驗，豐富的學習環境能夠\n促進經驗智力。（3）反省智力（reflective intelligence），指一個人使用和操縱其\n心理技能的能力，類似於元認知（metacognition，對自己的思維過程的認識和\n理解）和認知監視（cognitive monitoring，指任何旨在評價或調節自己的認知的\n活動）等概念；有助於有效地運用神經智力和經驗智力的控制系統cr。大模型\n恰恰具備上述三種主要成份或維度。所以，大模型不僅有智慧，而且是具有\n高智商的一種新載體。\n七\u3000大模型和「人的工具化」\n雖然大模型實現智慧的途徑和人類大腦並不一樣，但是最近美國約翰斯 ·\n霍普金斯大學（Johns Hopkins University）的專家發現，GPT-4可以利用思維鏈\n推理和逐步思考，有效證明了其心智理論性能。在一些測試中，人類的水平\n大概是87%，而GPT-4已經達到100%。此外，在適當的提示下，所有經過 \n基於人類回饋的強化學習訓練的模型都可以實現超過80%的準確率cs。如果\n人工智能互聯網化，或者互聯網人工智能化，無疑會推進智慧革命的積聚和\n深化。\n在現實生活中，大模型的衝擊正在全面顯現。例如，GPT作為一種基於\n大規模文本數據的生成式大模型，包括對語言學、符號學、人類學、哲學、\n心理學、倫理學和教育學等廣義思想文化領域的衝擊，對自然科學技術的全\n方位衝擊，進而對經濟形態及其運行的衝擊，對社會結構的衝擊，以及對國\n際關係的衝擊。此外，值得關注的是，人工智能已經開始進入金融領域，與\n加密數位貨幣結合。2020年，OpenAI聯合創始人奧特曼（Samuel H. Altman）\n推出名為「世界幣」（Worldcoin）的加密貨幣項目，期望通過人工智能技術支援\n的全球化金融公平與普惠的開源協定，支援私人數位身份和新的金融系統，\n「賦予人工智能時代的個人權力」。至2023年5月，超過一百五十萬人加入了\n加密貨幣錢包World App的測試階段，已經在八十多個國家或地區可用。\n現在，人類面臨的大模型挑戰，還不僅僅是職場動盪、失去工作、增加\n失業的問題，而是更為嚴酷的現實課題：人類是否或早或晚會成為大模型的\n工具人？不僅如此，如果人工智能出現推理能力，在無人知道原因的情況下\n越過界限，是否會發生人工智能確實傷害甚至消滅人類的潛在威脅？最近網\n上有這樣的消息：有人利用最新的AutoGPT開發出ChaosGPT，下達毀滅人類\n指令，人工智能自動搜索核武器數據，並招募其他人工智能輔助ct。\n大模型是人工智能歷史的分水嶺，甚至是工業革命以來人類文明史的分水 \n嶺：在這之前，人們更多關注和討論的是人類如何適應機器，以及和機器人合\n作，實現艾西莫夫（Isaac Asimov）的「機器人三定律」\n（Three Laws of Robotics）； \n現在進入如何理解大模型、如何預知人工智能的危險拐點，特別是某些人類\n\n44 \n二十一世紀評論\n和人工智能合作，反對另外的人類，甚至發生人工智能的徹底失控。人工智\n能聊天機器人（包括ChatGPT）即使經過數百萬文本源的訓練，可以閱讀並生\n成「自然語言」文本語言，但是就像人類自然地寫作或交談一樣，不幸的是它\n們也會犯錯。這些錯誤稱為「幻覺」，或者「幻想」。值得注意的是，因為人工\n智能幻覺的存在，很可能發生對人類決策和行為的誤導。\n正是在這樣的背景下，2023年3月29日，馬斯克（Elon R. Musk）聯名千\n餘名科技領袖，呼籲暫停開發人工智能，認為這是場危險競賽，讓我們從不\n斷湧現出具有新能力、不可預測的黑匣子模型中退後一步。據《紐約時報》\n（The New York Times）報導，身在多倫多的圖靈獎得主辛頓在4月向Google提\n出了請辭。辛頓離職的原因是為了能夠「自由地談論人工智能的風險」；他對\n自己畢生的工作感到後悔，「我用一個正常的理由安慰自己：如果我沒做，也\n會有別人這麼做的」。辛頓最大的擔憂是：人類只是智慧演變過程中的一個短\n暫階段，人工智能很可能比人類更聰明dk。未來的人工智能很可能對人類的\n存在構成威脅，所以停止發展人工智能也許是一個理性的做法，但不可能發\n生。人們應該合作，阻止人工智能的無序發展dl。對比GPT-4剛發布時，辛\n頓還是何等讚譽有加：「毛蟲吸取了足夠的養分，就能化繭成蝶，GPT-4就是\n人類的蝴蝶。」dm僅僅一個多月的時間，辛頓的立場發生如此逆轉，這不免讓\n人們想到第二次世界大戰之後，愛因斯坦（Albert Einstein）和奧本海默（Julius \nR. Oppenheimer）都明確表達了為參與核武器研發和提出建議感到後悔，更為\n核武器成為冷戰籌碼和政治威脅的工具感到強烈不滿。\n事實上，控制論之父維納（Norbert Wiener）在《人有人的用處——控制論\n和社會》（The Human Use of Human Beings: Cybernetics and Society）一書中認\n為，機器要在所有層面上取代人類，而非只是作為人類的工具提供替代性的\n力量，因此機器對於人類的影響是深遠的dn。霍金（Stephen Hawking）生前也\n曾多次表達他對人工智能可能導致人類毀滅的擔憂。\n遺憾的是，現在世界處於動盪時刻，人類已經自顧不暇，無人知曉人工\n智能的下一步會發生甚麼。《機械姬》（Ex Machina）是一部2015年上映的英國\n科幻電影，講述主人公受邀鑒定人形機器人是否具備人類心智所引發的故\n事，其中有這樣的蒼涼台詞：「將來有一天，人工智能回顧我們，就像我們回\n顧非洲平原的化石一樣，直立猿人住在塵土裏，使用粗糙的語言和工具，最\n後全部滅絕。」 \n近日有一個消息：來自瑞士洛桑聯邦理工學院（École polytechnique fédérale  \nde Lausanne）的研究團隊提出了一種全新的方法，可以用人工智能從大腦信號\n中提取視頻畫面，邁出了「讀腦術」的第一步。相關論文已於《自然》（Nature）\n雜誌刊登do。據說該文受到很多質疑，但可以肯定的是，不僅愈來愈多的科\n學家、工程師和企業家，包括天才，還可能有某些陰暗和邪惡力量，正在試\n圖影響和改變人工智能發展的方向和路徑，增加人們與日俱增的不安。如果\n說人工智能是人類的又一個潘朵拉盒子，很可能再無人能將其關上。\n\n二十一世紀評論 \n45\n在人類命運面臨的鉅變趨勢下，人類選擇在減少，然而不可放棄讓人回\n歸人的價值，需要留下種子——火星遷徙至少具有這樣的超前意識。\n八\u3000結語\n在人工智能1.0時代，人工智能數據來源是需要人工參與標註並且專注於\n特定領域的結構化數據；而在人工智能2.0時代，人工智能無需人工干預而能\n夠處理海量數據，具備跨領域的能力（圖5）。隨着大模型發展，人工智能從\n1.0時代加速進入2.0時代。\n圖片來源：筆者改製自〈創新工場李開復：AI 2.0已至，將誕生新平台並重寫所有應用〉（2023年\n3月14日），搜狐網，www.sohu.com/a/653951867_114778。\n圖5\u3000人工智能1.0和2.0\n在人工智能2.0時代，大模型分工愈來愈明確，日益增多的大模型，特別\n是開源大模型會實現不同的組合。支援大模型的數據不僅要求高品質，而且\n必須開源，任何與開源大模型的競爭必然注定失敗。前述Meta的LLaMA模型\n所支援的就是開源社區。\n可以預見的是，大模型規模的擴大存在着極限：一方面是物理性限制，\n一方面是大模型存在收益遞減的拐點。所以，大模型設計或架構需考慮如何\n引入控制論，以適應人類回饋。大模型將樂高（Lego）化，構成大模型集群，\n不僅推動人類社會、物理空間和信息空間日益緊密融合，而且正在生成一個\n大模型主導的世界（圖6）。\n在這樣的歷史時刻，我們需要重新認識生成主義（enactivism）。生成主義\n由瓦雷拉（Francisco J. Varela）、湯普森（Evan Thompson）和洛什（Eleanor Rosch） \n在《具身心智：認知科學和人類經驗》\n（The Embodied Mind: Cognitive Science and \nHuman Experience）中提出，主張心智能力是嵌入在神經和體細胞活動中的，\n並通過生物的行為而湧現dp。論者指出，「生成認知強調，我們所經驗的世界\n\n46 \n二十一世紀評論\n是有機體的物理構成、它的感覺運動能力和與環境本身互動的產物。有機體\n的世界不是一個預先給定的、客觀的、靜待有機體去『經驗』、『表徵』或『反\n映』的中性世界。相反，世界是通過有機體的行動或動作而生成的」dq。人工\n智能的生成式大模型，確實包括生成主義的要素。人工智能將給生成主義注\n入新的生命力。\n註釋\n1 John McCarthy et al., “A Proposal for the Dartmouth Summer Research Project \non Artificial Intelligence, August 31, 1955”, AI Magazine 27, no. 4 (2006): 12-14.\n2 對Jukebox的介紹, 參見https://openai.com/research/jukebox。\n3 2018年6月，OpenAI發布GPT-1，模型參數數量為1.17億；2019年2月，\n發布GPT-2， 模型參數數量為15億；2020年5月， 發布GPT-3， 參數數量為\n1,750億；2022年11月，正式推出了對話互動式的聊天機器人ChatGPT；2023年 \n3月，正式推出GPT-4，成為目前較先進的多模態大模型。GPT-4主要在識別理\n解能力、創作寫作能力、處理文本量以及自訂身份屬性迭代方面取得進展。\n4 CLIP（Contrastive Language-Image Pre-Training）模型是OpenAI在2021年\n初發布的用於匹配圖像和文本的預訓練神經網絡模型，可以說是近年來在多模態\n模型研究領域的經典之作。該模型直接使用大量的互聯網數據進行預訓練，在很\n多工作表現上達到了目前最高水平。關於預訓練，下文會有較詳細的討論。\n5 DALL‧E是一個可以根據書面文字生成圖像的人工智能系統，該名稱來源於\n著名畫家達利（Salvador Dalí）和電影《機器人總動員》（Wall‧E, 2008）。\n6 參見“Introducing ChatGPT”, https://openai.com/blog/chatgpt。\n7 強化學習（reinforcement learning）是機器學習（machine learning）的範式和\n方法論之一，用於描述和解決智能體（agent）在與環境的交互過程中通過學習策\n略以達成回報最大化或實現特定目標的問題。\n8 中文將“Transformer”翻譯為變換器，並不能完全反映大模型的Transformer\n的基本內涵。所以，本文還是直接使用英文原詞。\n圖6\u3000人類社會、物理空間、信息空間三重視角下的大模型\n圖片來源：筆者改製自 Shiqiang Zhu et al., “Intelligent Computing: The Latest Advances, Challenges,  \nand Future”, Intelligent Computing, vol. 2 (January 2023), http://dol.org/10.34133/icomputing.0006。\n\n二十一世紀評論 \n47\n9 生成性模型從一個形式語言系統出發，生成語言的某一集合。代表是喬姆斯\n基（Avram N. Chomsky）的形式語言理論和轉換語法。分析性模型從語言的某一\n集合開始，根據對這個集合中各個元素的性質的分析，闡明這些元素之間的關\n係，並在此基礎上用演繹的方法建立語言的規則系統。代表是前蘇聯數學家庫拉\n金娜（O. S. Kulagina）和羅馬尼亞數學家馬爾庫斯（Solomon Marcus）用集合論方\n法提出的語言模型。在生成性模型和分析性模型的基礎上，將二者結合起來，產\n生了一種很有實用價值的模型，即辨識性模型。辨識性模型可以從語言元素的某\n一集合及規則系統出發，通過有限步驟的運算，確定語言中合格的句子。代表是\n巴爾—希列爾（Yehoshua Bar-Hillel）用數理邏輯方法提出的句法類型演算模型。\nbk 自監督學習是一種機器學習範式和相應的方法，用於處理未標註的數據，以\n獲得有助於下游學習任務的有用表示。\nbl Google推出的LaMDA（Language Model for Dialogue Applications）是自然 \n語言處理領域的一項新的研究突破。它是一個面向對話的神經網絡架構，可 \n以就無休止的主題進行自由流動的對話。它的開發是為了克服傳統聊天機器人\n的局限性，後者在對話中往往遵循狹窄的、預定義的路徑。BERT（Bidirectional \nEncoder Representation from Transformers）是一個預訓練的語言表徵模型。它\n強調了不再像以往一樣採用傳統的單向語言模型或者把兩個單向語言模型進行淺\n層拼接的方法進行預訓練，而是採用新的「屏蔽語言模型」（Masked Language \nModel, MLM），以致能生成深度的雙向語言表徵。關於BERT的論文發表時，提\n及BERT在十一個自然語言處理任務中獲得了新的目前最高水平的結果PaLM-E，\n參數數量高達5,620億（GPT-3的參數數量為1,750億），同時集成語言和視覺，\n用於機器人控制。相比大語言模型，它被稱為視覺語言模型（Visual Language \nModel, VLM）。兩者不同之處，在於後者對物理世界是有感知的。\nbm LLaMa（Large Language Model Meta AI）有多個不同大小的版本。該模型主\n要從維基百科、書籍，以及來自arXiv、GitHub、Stack Exchange 和其他網站的學 \n術論文中收集的數據集上進行訓練。LLaMA模型支援二十種語言，包括拉丁語和\n西里爾字母語言，目前看原始模型並不支援中文。2023年3月，LLaMa模型發生\n洩露，意外促成了大批ChatGPT式服務的產生。OPT-175B模型的參數數量超過\n1,750億，和GPT-3相當。OPT是“Open Pre-trained Transformer”的縮寫。它的\n優勢在於完全免費，這使得更多缺乏相關經費的科學家可以使用這個模型。同時， \nMeta還公布了代碼庫。\nbn 參見Nick Bostrom, Superintelligence: Paths, Dangers, Strategies (Oxford: \nOxford University Press, 2014)。\nbo Melinda Bognár, “Prospects of AI in Architecture: Symbolicism, Con-\nnectionism, Actionism” (10 January 2021), Journal of Architectural Informatics \nSociety, https://openreview.net/pdf?id=gvHffM4DlpG.\nbp A. M. Turing, “Computing Machinery and Intelligence”, Mind LIX, issue 236 \n(1950): 433-60.\nbq A. L. Samuel, “Some Studies in Machine Learning Using the Game of \nCheckers”, IBM Journal of Research and Development 44, no. 1/2 (2000): 206-\n26.\nbr Ryszard S. Michalski, Jaime G. Carbonell, and Tom M. Mitchell, eds., \nMachine Learning: An Artificial Intelligence Approach, vol. II (Los Altos, CA: \nMorgan Kaufmann, 1986).\nbs 這一階段代表性的工作有莫斯托（Jack Mostow）的指導式學習、萊納特\n（Douglas B. Lenat）的數學概念發現程式、蘭利（Pat Langley）的BACON程式及\n其改進程式。\nbt Geoffrey E. Hinton, Simon Osindero, and Yee-Whye Teh, “A Fast Learning \nAlgorithm for Deep Belief Nets”, Neural Computation 18, no. 7 (2006): 1527-54.\nck 在文本資料中，包括有標註數據和無標註數據，這是所謂數據驅動。\n\n48 \n二十一世紀評論\ncl Jason Wei et al., “Emergent Abilities of Large Language Models”, Transactions  \non Machine Learning Research (August 2022), https://openreview.net/forum? \nid=yzkSU5zdwD.\ncm 貝葉斯原理是用貝葉斯風險（Bayes Risk）表示的最優決策律；馬爾可夫鏈描 \n述的是概率論和數理統計中的離散的指數集（index set）和狀態空間（state space） \n內的隨機過程（stochastic process）；N元模型是大詞彙連續語音辨識中常用的一\n種語言模型。\ncn Cage：〈Pinecone：大模型引發爆發增長的向量數據庫，AI Agent的海馬體〉 \n（2023年4月26日），「海外獨角獸」微信公眾號，https://mp.weixin.qq.com/s?__biz= \nMzg2OTY0MDk0NQ==&mid=2247501819&idx=1&sn=2fcee248cf2b9703804e\n6d9a45dc4c97。\nco Ashish Vaswani et al., “Attention Is All You Need” (6 December 2017), arXiv,  \nhttps://doi.org/10.48550/arXiv.1706.03762.\ncp 〈人類已達硅計算架構上限！預計2030年，AI會消耗全球電力供應的50%〉 \n（2023年3月27日），「新智元」微信公眾號，https://mp.weixin.qq.com/s/k9A8d2g \nX14xyE5cSBl-Dpw；王鵬：〈雙碳視角下人工智能發展再思考——投產相抵還是 \n能耗脅迫？〉\n（2023年4月9日），《中國日報》網，https://column.chinadaily.com.cn/ \na/202304/09/WS6432bc56a3102ada8b2376fa.html。\ncq Donald O. Hebb, The Organization of Behavior: A Neuropsychological \nTheory (Mahwah, NJ: Psychology Press, 2002).\ncr David N. Perkins, Outsmarting IQ: The Emerging Science of Learnable \nIntelligence (New York: Free Press, 1995).\ncs 〈100:87：GPT-4心智碾壓人類！三大GPT-3.5變種難敵〉\n（2023年5月1日）， \n「新智元」微信公眾號，https://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==& \nmid=2652326060&idx=1&sn=c0ffa5d76ee8af079a2dbbe4b37bb15f。\nct 〈有人給了AI「毀滅人類」的任務，讓它持續自主運行，它開始研究最強核武器〉 \n（2023年4月9日），騰訊網，https://new.qq.com/rain/a/20230409A07GZ100。\ndk Cade Metz, “‘The Godfather of A.I.’ Leaves Google and Warns of Danger \nAhead”, The New York Times, 1 May 2023.\ndl 部夢凡整理：〈人工智能教父：也許還有希望限制AI的無序發展〉（2023年 \n5月13日），新浪財經網，https://finance.sina.com.cn/stock/hyyj/2023-05-13/doc- \nimytrira2549050.shtml.\ndm Founder Park：〈「AI教父」離職谷歌：對畢生工作感到後悔和恐懼〉（2023年\n5月2日），「極客公園」微信公眾號，https://mp.weixin.qq.com/s?__biz=MTMwN\nDMwODQ0MQ==&mid=2652991276&idx=1&sn=950b2e53feae3ceb7c7c03b3\n9eb4a1a9。\ndn 維納（Norbert Wiener）著，陳步譯：《人有人的用處——控制論和社會》\n（北京： \n商務印書館，1978）。\ndo Sara Reardon, “Mind-reading Machines Are Here: Is It Time to Worry?”, \nNature 617, no. 7960 (2023): 236.\ndp 參見Francisco J. Varela, Evan Thompson, and Eleanor Rosch, The Embodied  \nMind: Cognitive Science and Human Experience (Cambridge, MA: MIT Press, \n1991)。\ndq 葉浩生、曾紅、楊文登：〈生成認知：理論基礎與實踐走向〉，《心理學報》，\n2019年第11期，頁1270-80。\n朱嘉明\u3000經濟學博士、教授，曾任職於聯合國工業發展組織（UNIDO），並先\n後任教於維也納大學和台灣大學。現任「數字資產研究院」學術與技術委員會\n主席，中國投資協會數字資產研究中心專家組組長。'}, 'traceback': None, 'children': [], 'date_done': '2025-01-31T03:51:01.830485', 'task_id': '441a8496-35e1-4471-a277-e950c42fff3b'}
INFO:     127.0.0.1:48944 - "GET /api/summary/441a8496-35e1-4471-a277-e950c42fff3b HTTP/1.1" 200 OK
